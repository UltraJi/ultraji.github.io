{"pages":[{"title":"关于我","text":"你可以不自己造轮子，但应该了解轮子的构造。","link":"/about/index.html"}],"posts":[{"title":"Linux C 可变参数在x86和x64下的区别与实现原理","text":"在x86平台下，va_list可变传参是通过栈来进行；在x64平台下，va_list可变传参是默认的调用约定。会带来什么影响呢？ 通过看对应的汇编代码实现和Intel ABI手册，可以得出： 在x86平台下，va_list可变传参是通过栈来进行； 在x64平台下，va_list可变传参是默认的调用约定（calling convention）； 一、从汇编代码分析1234567891011121314151617181920212223242526#include &lt;stdio.h&gt;#include &lt;stdarg.h&gt;long add(long num, ...){ long sum = 0, i, tmp; va_list va; va_start(va, num); for (i = 0; i &lt; num; i++) { tmp = va_arg(va, int); sum += tmp; printf(\"%ld \", tmp); } printf(\"\\n\"); va_end(va); return sum;}int main(){ long sum = add(7, 2, 3, 4, 5, 6, 7, 8); printf(\"sum is %ld\\n\", sum); return 0;} 结果： 在64位和32位下输出结果一样。 首先看一下32位编译情况， 12gcc -m32 -c test.cobjdump -d test.o 结果如下： 然后看一下64位编译情况， 12gcc -c test.cobjdump -d test.o 结果如下： 二、官方说明在32位上，va_list的定义为: 12//注意，由于中间宏过多，这里省去了中间如_VA_LIST宏，直接给出实际定义。typedef va_list char**; 在64位下，va_list的定义为: 123456 typedef struct { unsigned int gp_offset; unsigned int fp_offset; void *overflow_arg_area; void *reg_save_area;} va_list[1]; 然后再看一下Inter官方的Linux ABI文档（64位）怎么说，问题在abi中已经解释的很清楚了。 The va_start MacroThe va_start macro initializes the structure as follows: reg_save_area The element points to the start of the register save area. overflow_arg_area This pointer is used to fetch arguments passed on the stack. It is initialized with the address of the first argument passed on the stack, if any, and then always updated to point to the start of the next argument on the stack. gp_offset The element holds the offset in bytes from reg_save_area to the place where the next available general purpose &gt;argument register is saved. In case all argument registers have been exhausted, it is set to the value 48 (6 ∗ 8). fp_offset The element holds the offset in bytes from reg_save_area to the place where the next available floating point &gt;argument register is saved. In case all argument registers have been exhausted, it is set to the value 304 (6 ∗ 8 + 16 ∗ 16). 三、再看一下什么情况下可能出错123456789101112131415161718192021222324#include &lt;stdio.h&gt;#include &lt;stdarg.h&gt;long add(long num, ...){ long sum = 0, i, tmp; long *arg = &amp;num + 1; for (i = 0; i &lt; num; i++) { tmp = arg[i]; sum += tmp; printf(\"%ld \", tmp); } printf(\"\\n\"); return sum;}int main(){ long sum = add(7, 2, 3, 4, 5, 6, 7, 8); printf(\"sum is %ld\\n\", sum); return 0;} 64位下结果为随机 120 1 140733246434352 140733246434352 0 2 3sum is 281466492868710 32位下结果正确 122 3 4 5 6 7 8sum is 35","link":"/2019/03/linux_c_va_list_in_x86_and_x64.html"},{"title":"编程科普 - 字符与编码","text":"计算机中储存的信息都是用二进制数表示的。通俗的说，按照何种规则将字符存储在计算机中，称为”编码”；反之，将二进制数解析显示出来，称为”解码”。 一、基本概念字符集（Charset）：是一个系统支持的所有抽象字符的集合。字符是各种文字和符号的总称，包括各国家文字、标点符号、图形符号、数字等。常见的字符集有ASCII字符集、GB2312字符集、Unicode字符集。 字符编码（Character Encoding）：是一套法则，使用该法则能够对自然语言的字符的一个集合（如字母表或音节表），与其他东西的一个集合（如号码或电脉冲）进行配对。即在符号集合与数字系统之间建立对应关系，它是信息处理的一项基本技术。 二、编码模型2.1. ASCII字符集与编码ASCII字符集：主要包括控制字符（回车键、退格、换行键等）；可显示字符（英文大小写字符、阿拉伯数字和西文符号）。 ASCII编码：将ASCII字符集转换为计算机可以接受的数字系统的数的规则。使用7位（bits）表示一个字符，共128字符；但是7位编码的字符集只能支持128个字符，为了表示更多的欧洲常用字符对ASCII进行了扩展，ASCII扩展字符集使用8位（bits）表示一个字符，共256字符。 2.2. 再讲讲 Unicode 和 UTF-32、UTF-16、UTF-8简单来说：Unicode是字符集，UTF-32、UTF-16、UTF-8是三种字符编码方案。 2.2.1 Unicode字符集当计算机传到世界各个国家时，为了适合当地语言和字符，例如中国设计和实现GB2312/GBK/GB18030/BIG5的编码方案。每个地区这样各搞一套，在本地使用没有问题，一旦出现在网络中，由于不兼容，互相访问就出现了乱码现象。 为了解决这个问题，一个伟大的创想产生了 —— Unicode。Unicode字符集为表达任意语言的任意字符而设计。它使用4字节的数字来表达每个字母、符号，或者表意文字(ideograph)。每个数字代表唯一的至少在某种语言中使用的符号（并不是所有的数字都用上了，但是总数已经超过了65535，所以2个字节是不够用的）。即每个字符对应一个数字，每个数字对应一个字符，不存在二义性。例如，U+0041总是代表’A’，即使这种语言没有’A’这个字符。 2.2.2 UTF-32编码编码方式：每个字符都使用4字节。 就空间而言，是非常没有效率的。这种方法的优点就是可以在常数时间内定位字符串里的第N个字符。 2.2.3 UTF-16编码尽管有Unicode字符非常多，但是实际上大多数人不会用到超过前65535个以外的字符。因此，就有了另外一种Unicode编码方式，叫做UTF-16。UTF-16将0–65535范围内的字符编码成2个字节，如果真的需要表达那些很少使用的”星芒层(astral plane)”内超过这65535范围的Unicode字符，则需要使用一些诡异的技巧来实现。 编码方式： 如果字符编码U小于0x10000，也就是十进制的0到65535之内，则直接使用1个两字节表示； 如果字符编码U大于0x10000，由于UNICODE编码范围最大为0x10FFFF，从0x10000到0x10FFFF之间共有0xFFFFF个编码，也就是需要20个bit就可以标示这些编码。用U’表示从0-0xFFFFF之间的值，将其前10 bit作为高位和16bit的数值0xD800进行逻辑or操作，将后10bit作为低位和0xDC00做逻辑or操作，这样组成的2个两字节就构成了U的编码。 UTF-16编码最明显的优点是它在空间效率上比UTF-32高两倍，因为每个字符只需要2个字节来存储（除去65535范围以外的），而不是UTF-32中的4个字节。并且，如果我们假设某个字符串不包含任何星芒层中的字符，那么我们依然可以在常数时间内找到其中的第N个字符，直到它不成立为止这总是一个不错的推断。 2.2.4 UTF-8编码UTF-8（8-bit Unicode Transformation Format）是一种针对Unicode的可变长度字符编码，也是一种前缀码。它可以用来表示Unicode标准中的任何字符，且其编码中的第一个字节仍与ASCII兼容，这使得原来处理ASCII字符的软件无须或只须做少部份修改，即可继续使用。因此，它逐渐成为电子邮件、网页及其他存储或传送文字的应用中，优先采用的编码。互联网工程工作小组（IETF）要求所有互联网协议都必须支持UTF-8编码。 编码方式： 使用1至4个字节作为每个字符编码： 128个US-ASCII字符只需1字节编码（Unicode范围由U+0000至U+007F）。 带有附加符号的拉丁文、希腊文、西里尔字母、亚美尼亚语、希伯来文、阿拉伯文、叙利亚文及它拿字母则需要2字节编码（Unicode范围由U+0080至U+07FF）。 其他基本多文种平面（BMP）中的字符（这包含了大部分常用字）使用3字节编码。 其他极少使用的Unicode辅助平面的字符使用4字节编码。 2.2.5 总结对于UTF-32和UTF-16编码方式还有一些其他不明显的缺点。不同的计算机系统会以不同的顺序保存字节。以UTF-16为例，这意味着字符U+4E2D（称为编码单元）可能被保存为4E 2D或者2D 4E（即这个编码单元为2字节，而编码单元内部的字节顺序不确定），这取决于该系统使用的是大尾端还是小尾端。 UTF-8则不会有这种问题(因为utf8是变长编码，而且是单字节为编码单元，不存在谁在高位、谁在低位的问题，所以不存在顺序问题。顺便说一下解码，由于utf8的首字节记录了总字节数（比如3个），所以读取首字节后，再读取后续字节（2个），然后进行解码，得到完整的字节数，从而保证解码也是正确的)。","link":"/2019/05/charset_and_encoding.html"},{"title":"编程科普 - C代码到C程序","text":"耳熟能详的“Hello World”程序，基本上成了程序入门的必写程序。本文用Hello World程序探究被隐藏的编译过程。 1234567#include &lt;stdio.h&gt;int main(){ printf(\"Hello World\\n\"); return 0;} 对应这段代码而言，在windows的集成开发环境IDE下，我们可能只需要按下RUN或BUILD按钮，这段代码就被编译运行了。同样在Linux下，一个gcc hello.c命令就完成了所有工作。 事实上，上述过程可以分解为4个步骤，分别是预处理（Prepressing）、编译（Compilation）、汇编（Assembly）和链接（Linking）。 被隐藏的过程gcc这个命令只是这些后台程序的包装，它会根据不同的参数要求去调用预编译编译程序cc1、汇编器as、链接器ld。 预编译首先是hello.c和相关的头文件，如stdio.h等被预编译器cpp预编译成一个.i文件。对于C++程序来说，源代码文件的扩展名可能是.cpp或.cxx，头文件的扩展名可能是.hpp，而预编译后的文件扩展名是.ii。 123gcc –E hello.c –o hello.i# 或cpp hello.c &gt; hello.i 预编译过程主要处理那些源代码文件中的以#开始的预编译指令。 将所有的#define删除，并且展开所有的宏定义。 处理所有条件预编译指令，比如#if、#ifdef、#elif、#else、#endif。 处理#include预编译指令，将被包含的文件插入到该预编译指令的位置。注意，这个过程是递归进行的，也就是说被包含的文件可能还包含其他文件。 删除所有的注释//和/* */。 添加行号和文件名标识，比如#2&quot;hello.c&quot;2，以便于编译时编译器产生调试用的行号信息及用于编译时产生编译错误或警告时能够显示行号。 保留所有的#pragma编译器指令，因为编译器须要使用它们。 编译编译过程就是把预处理完的文件进行一系列词法分析、语法分析、语义分析及优化后生产相应的汇编代码文件，这个过程是整个程序构建的核心部分。 12345gcc –S hello.i –o hello.s# 或（路径可能不一样）/usr/lib/gcc/x86_64-linux-gnu/7/cc1 hello.i# 或直接从.c到.sgcc –S hello.c –o hello.s 编译过程一般可以分为6步：扫描、语法分析、语义分析、源代码优化、代码生成和目标代码优化。 以array[index] = (index + 4) * (2 + 6)为例， 词法分析：首先源代码程序被输入到扫描器（Scanner），扫描器的任务很简单，它只是简单地进行词法分析，运用一种类似于有限状态机（Finite State Machine）的算法将字符序列分割成一系列的记号（Token）。产生的记号一般可以分为如下几类：关键字、标识符、字面量（包含数字、字符串等）和特殊符号（如加号、等号）。在识别记号的同时，扫描器也完成了其他工作。比如将标识符存放到符号表，将数字、字符串常量存放到文字表等。 记号 类型 array 标识符 [ 左方括号 index 标识符 ] 右方括号 = 赋值 ( 左圆括号 index 标识符 + 加号 4 数字 ) 右圆括号 * 乘号 ( 左圆括号 2 数字 + 加号 6 数字 ) 右圆括号 语法分析：语法分析器（Grammar Parser）将对由扫描器产生的记号进行语法分析，从而产生语法树（Syntax Tree）。 如果出现了表达式不合法，比如各种括号不匹配、表达式中缺少操作符等，编译器就会报告语法分析阶段的错误。 语法分析仅仅是完成了对表达式的语法层面的分析，但是它并不了解这个语句是否真正有意义。比如C语言里面两个指针做乘法运算是没有意义的，但是这个语句在语法上是合法的。 语义分析：编译器所能分析的语义是静态语义（Static Semantic），所谓静态语义是指在编译期可以确定的语义，与之对应的动态语义（Dynamic Semantic）就是只有在运行期才能确定的语义。 静态语义通常包括声明和类型的匹配，类型的转换。比如当一个浮点型赋值给一个整型时，语义分析需要完成这个类型转换。比如将一个浮点型赋值给一个指针，编译器将会报错。动态语义一般指在运行期出现的语义相关的问题，比如将0作为除数是一个运行期语义错误。 经过语义分析阶段以后，整个语法树的表达式都被标识了类型，如果有些类型需要做隐式转换，语义分析程序会在语法树中插入相应的转换节点。 中间代码优化：源代码优化器往往将整个语法树转换成中间代码（Intermediate Code），它是语法树的顺序表示。中间代码有很多种类型，比较常见的有：三地址码（Three-address Code）和P-代码（P-Code）。最基本的三地址码是这样的：x = y op z。则语法树对应下面的代码。 1234t1 = 2 + 6t2 = index + 4t3 = t2 * t1array[index] = t3 而t1 = 2 + 6将直接被优化成t1 = 8。则对应语法树为 目标代码生成：代码生成器将中间代码转换成目标机器代码，这个过程十分依赖于目标机器，因为不同的机器有着不同的字长、寄存器、整数数据类型和浮点数数据类型等。 12345movl index, %ecx ; value of index to ecxaddl $4, %ecx ; ecx = ecx + 4mull $8, %ecx ; ecx = ecx * 8movl index, %eax ; value of index to eaxmovl %ecx, array(,eax,4) ; array[index] = ecx 目标代码优化：目标代码优化器对上述的目标代码进行优化，比如选择合适的寻址方式、使用位移来代替乘法运算、删除多余的指令等。上面的例子中，乘法由一条相对复杂的基址比例变址寻址（Base Index Scale Addressing）的lea指令完成，随后由一条mov指令完成最后的赋值操作，这条mov指令的寻址方式与lea是一样的。 123movl index, %edxleal 32(,%edx,8), %eaxmovl %eax, array(,%edx,4) 现代的编译器有着异常复杂的结构，主要原因有： 现代高级编程语言本身非常地复杂 现代的计算机CPU相当地复杂，CPU本身采用了诸如流水线、多发射、超标量等诸多复杂的特性 有些编译器支持多种硬件平台，即允许编译器编译出多种目标CPU的代码 在这里，仍然存在一个明显的问题：如何确定index和array的地址。如果index和array定义在这个编译单元中，又如果index和array定义在其他模块中。这个问题将在链接过程中得到解决。 汇编每一个汇编语句几乎都对应一条机器指令。汇编过程比较简单，只需要根据汇编指令和机器指令的对照表一一翻译就可以了。 123as hello.s –o hello.o# 或gcc –c hello.c –o hello.o 链接通过以下命令即可查看最后的链接工作。 1gcc -v -o a.out hello.c 可以看到以下打印 12.../usr/lib/gcc/x86_64-linux-gnu/7/collect2 -plugin /usr/lib/gcc/x86_64-linux-gnu/7/liblto_plugin.so -plugin-opt=/usr/lib/gcc/x86_64-linux-gnu/7/lto-wrapper -plugin-opt=-fresolution=/tmp/ccHwQCoj.res -plugin-opt=-pass-through=-lgcc -plugin-opt=-pass-through=-lgcc_s -plugin-opt=-pass-through=-lc -plugin-opt=-pass-through=-lgcc -plugin-opt=-pass-through=-lgcc_s --sysroot=/ --build-id --eh-frame-hdr -m elf_x86_64 --hash-style=gnu --as-needed -dynamic-linker /lib64/ld-linux-x86-64.so.2 -pie -z now -z relro -o a.out /usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/Scrt1.o /usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/crti.o /usr/lib/gcc/x86_64-linux-gnu/7/crtbeginS.o -L/usr/lib/gcc/x86_64-linux-gnu/7 -L/usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu -L/usr/lib/gcc/x86_64-linux-gnu/7/../../../../lib -L/lib/x86_64-linux-gnu -L/lib/../lib -L/usr/lib/x86_64-linux-gnu -L/usr/lib/../lib -L/usr/lib/gcc/x86_64-linux-gnu/7/../../.. /tmp/ccNFWFTe.o -lgcc --push-state --as-needed -lgcc_s --pop-state -lc -lgcc --push-state --as-needed -lgcc_s --pop-state /usr/lib/gcc/x86_64-linux-gnu/7/crtendS.o /usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/crtn.o collect2即为链接器ld的封装，在这个命令之后才最终生成了可执行的Hello World程序。需要将一大堆文件链接起来才可以得到“a.out”。 第一个问题的出现与解决：程序并不是一写好就永远不变化的在用机器语言编程的时代，比如我们在第1条指令和第5条指令之间插入了一条或多条指令，那么第5条指令及之后指令的位置将会相应地往后移动，指令低4位的数字将相应地调整。在这个过程中，程序员需要人工重新计算每个子程序或跳转的目标地址。这种重新计算各个目标的地址过程被叫做重定位（Relocation）。 先驱者发明了汇编语言。于是，我们将第5行开始的子程序命名为foo，如果我们只要jmp foo就可以跳转到对应子程序运行，无需在乎foo之前插入或减少了多少条指令，汇编器在汇编程序的时候会重新计算foo这个符号的地址，然后把所有引用到foo的指令修正到这个正确的地址。由汇编器来完成这个重定位工作，那么将“极大地解放了生产力”。 第二个问题的出现与解决：将所有代码写在同一个文件中，文件将大到难以维护汇编语言出现后，生产力大大提高，软件的规模也开始日渐庞大，代码量也已经开始快速地膨胀，导致人们要开始考虑将不同功能的代码以一定的方式组织起来，使得更加容易阅读和理解，以便于日后修改和重复使用。自然而然，人们开始将代码按照功能或性质划分，分别形成不同的功能模块，不同的模块之间按照层次结构或其他结构来组织。 在一个程序被分割成多个模块以后，这些模块之间最后如何组合形成一个单一的程序成为了须解决的问题。模块之间如何组合的问题可以归结为模块之间如何通信的问题，最常见的属于静态语言的C/C++模块之间通信有两种方式，一种是模块间的函数调用，另外一种是模块间的变量访问。函数访问须知道目标函数的地址，变量访问也须知道目标变量的地址，所以这两种方式都可以归结为一种方式，那就是模块间符号的引用。这个模块的拼接过程就是链接（Linking）。 链接器的工作从原理上来讲，链接器的工作无非就是把一些指令对其他符号地址的引用加以修正。链接过程主要包括了地址和空间分配（Address and Storage Allocation）、符号决议（Symbol Resolution）和重定位（Relocation）等这些步骤。 例如，我们在A文件中定义一个变量var，在B文件中使用。B的目标文件中有这么一条指令 1movl $0x2a,var 由于编译器编译目标文件B时，并不知道var的目标地址，所以在没法确定地址的情况下，将这条mov指令的目标地址置为0，等待链接器在将目标文件A和B链接起来的时候再将其修正。 我们假设A和B链接后，变量var的地址确定下来为0x1000，那么链接器将会把这个指令的目标地址部分修改成0x1000。这个地址修正的过程也被叫做重定位（Relocation），每个要被修正的地方叫一个重定位入口（Relocation Entry）。 参考 《程序员的自我修养 –链接、装载与库》","link":"/2019/05/c_code_to_c_program.html"},{"title":"编程科普 - ELF文件结构（一）","text":"真正了不起的程序员对自己的程序的每一个字节都了如指掌。 现在PC平台流行的可执行文件格式（Executable）主要是Windows的PE（Portable Executable）和Linux的ELF（Executable Linkable Format），它们都是COFF（Common file format）格式的变种。 ELF文件标准里面把系统中采用ELF格式的文件归为4类。 ELF文件类型 说明 实例 可重定位文件（Relocalable File） 这类文件包含代码和数据，可以被用来链接成可执行文件或共享目标文件，静态文件也可以归为该类 linux的.o windows的.obj 可执行文件（Executable File） 直接可以运行的程序，linux下一般没有扩展名 例如/bin/bash，windows的.exe 共享目标文件（Shared Object File） 这类文件使用的两种情况：跟其他的可重定位文件和共享文件链接，产生新的目标文件；或由动态链接器加载，作为进程映像的一部分来运行 linux的.so、windows的.dll 核心转储文件（Core Dump File） 当进程意外终止时的核心转储文件 linux下的core dump linux下可通过file命令查看文件格式，例如 12$file /bin/bash/bin/bash: ELF 64-bit LSB shared object, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/l, for GNU/Linux 3.2.0, BuildID[sha1]=12f73d7a8e226c663034529c8dd20efec22dde54, stripped C代码文件与目标文件这个SimpleSection.c是一个具有代表性的C代码文件，通过gcc -c SimpleSection.c可以生成对应的目标文件。 1234567891011121314151617181920int printf( const char* format, ... );int global_init_var = 84;int global_uninit_var;void func1( int i ) { printf( \"%d\\n\", i );}int main(void){ static int static_var = 85; static int static_var2; int a = 1; int b; func1( static_var + static_var2 + a + b ); return a;} 一般C代码文件编译后 执行语句都会被编译成机器代码保存在.text段； 已初始化的全局变量和局部静态变量都保存在.data段； 未初始化或初始化为0的全局变量和局部静态变量一般放在.bss段。 程序运行的时候，未初始化的全局变量和局部静态变量是要占内存空间的，并且可执行文件必须记录它们的大小总和，记为.bss段。 .bss段只是为未初始化的全局变量和局部静态变量预留位置而已，它并没有内容，所以它在文件中也不占据空间。 除此之外，还可以看到一个“文件头”，它描述了整个文件的文件属性，包括文件是否可执行、是静态链接还是动态链接及入口地址（如果是可执行文件）、目标硬件、目标操作系统等信息，文件头还包括一个段表（Section Table）。段表其实是一个描述文件中各个段的数组，描述了文件中各个段在文件中的偏移位置及段的属性等。 为什么要区分代码段和数据段？ 权限：当程序被装载后，数据和指令分别被映射到两个虚存区域。对于程序而言，数据段是可读写的，而代码段是只读的，据此可以设置两个虚存区域的权限； 局部性原理：现代的CPU来说，它们有着极为强大的缓存（Cache）体系，且一般都被设计成数据缓存和指令缓存分离。指令区和数据区的分离有利于提高程序的局部性。 共享：有利于指令的共享。当系统中运行着多个该程序的副本时，它们的指令都是一样的，所以内存中只须要保存一份该程序的指令部分。 与程序运行密切相关的段结构在Linux下，我们可以使用binutils的工具objdump来查看object内部的结构， 1234567891011121314151617181920$objdump -h SimpleSection.oSimpleSection.o： 文件格式 elf64-x86-64节：Idx Name Size VMA LMA File off Algn 0 .text 00000057 0000000000000000 0000000000000000 00000040 2**0 CONTENTS, ALLOC, LOAD, RELOC, READONLY, CODE 1 .data 00000008 0000000000000000 0000000000000000 00000098 2**2 CONTENTS, ALLOC, LOAD, DATA 2 .bss 00000004 0000000000000000 0000000000000000 000000a0 2**2 ALLOC 3 .rodata 00000004 0000000000000000 0000000000000000 000000a0 2**0 CONTENTS, ALLOC, LOAD, READONLY, DATA 4 .comment 0000002c 0000000000000000 0000000000000000 000000a4 2**0 CONTENTS, READONLY 5 .note.GNU-stack 00000000 0000000000000000 0000000000000000 000000d0 2**0 CONTENTS, READONLY 6 .eh_frame 00000058 0000000000000000 0000000000000000 000000d0 2**3 CONTENTS, ALLOC, LOAD, RELOC, READONLY, DATA 先不管其他段，只研究.text、.data、.bss段，每个段的第2行内容为段的属性。“CONTENTS”表示该段在文件中存在。.bss段没有该属性，表示它在ELF文件中不存在内容。根据段的长度（Size）和段所在的位置（File Offset），我们可以画出ELF文件的大致结构 size命令可以用来查看ELF文件的代码段、数据段和BSS段的长度（注：size默认是运行在“Berkeley compatibility mode”下。在这种模式下，会将不可执行的拥有“ALLOC”属性的只读段归到.text段下，在这里就是.rodata段和.eh_frame段。如果你使用-A选项，那么size会运行在“System V compatibility mode”，此时就跟objdump -h显示的.text段的大小差不多了）。 1234567891011$size -A SimpleSection.oSimpleSection.o :section size addr.text 87 0.data 8 0.bss 4 0.rodata 4 0.comment 44 0.note.GNU-stack 0 0.eh_frame 88 0Total 235 通过objdump -s -d SimpleSection.o打印所有段的信息 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758SimpleSection.o： 文件格式 elf64-x86-64Contents of section .text: 0000 554889e5 4883ec10 897dfc8b 45fc89c6 UH..H....}..E... 0010 488d3d00 000000b8 00000000 e8000000 H.=............. 0020 0090c9c3 554889e5 4883ec10 c745f801 ....UH..H....E.. 0030 0000008b 15000000 008b0500 00000001 ................ 0040 c28b45f8 01c28b45 fc01d089 c7e80000 ..E....E........ 0050 00008b45 f8c9c3 ...E... Contents of section .data: 0000 54000000 55000000 T...U... Contents of section .rodata: 0000 25640a00 %d.. Contents of section .comment: 0000 00474343 3a202855 62756e74 7520372e .GCC: (Ubuntu 7. 0010 342e302d 31756275 6e747531 7e31382e 4.0-1ubuntu1~18. 0020 30342e31 2920372e 342e3000 04.1) 7.4.0. Contents of section .eh_frame: 0000 14000000 00000000 017a5200 01781001 .........zR..x.. 0010 1b0c0708 90010000 1c000000 1c000000 ................ 0020 00000000 24000000 00410e10 8602430d ....$....A....C. 0030 065f0c07 08000000 1c000000 3c000000 ._..........&lt;... 0040 00000000 33000000 00410e10 8602430d ....3....A....C. 0050 066e0c07 08000000 .n...... Disassembly of section .text:0000000000000000 &lt;func1&gt;: 0: 55 push %rbp 1: 48 89 e5 mov %rsp,%rbp 4: 48 83 ec 10 sub $0x10,%rsp 8: 89 7d fc mov %edi,-0x4(%rbp) b: 8b 45 fc mov -0x4(%rbp),%eax e: 89 c6 mov %eax,%esi 10: 48 8d 3d 00 00 00 00 lea 0x0(%rip),%rdi # 17 &lt;func1+0x17&gt; 17: b8 00 00 00 00 mov $0x0,%eax 1c: e8 00 00 00 00 callq 21 &lt;func1+0x21&gt; 21: 90 nop 22: c9 leaveq 23: c3 retq 0000000000000024 &lt;main&gt;: 24: 55 push %rbp 25: 48 89 e5 mov %rsp,%rbp 28: 48 83 ec 10 sub $0x10,%rsp 2c: c7 45 f8 01 00 00 00 movl $0x1,-0x8(%rbp) 33: 8b 15 00 00 00 00 mov 0x0(%rip),%edx # 39 &lt;main+0x15&gt; 39: 8b 05 00 00 00 00 mov 0x0(%rip),%eax # 3f &lt;main+0x1b&gt; 3f: 01 c2 add %eax,%edx 41: 8b 45 f8 mov -0x8(%rbp),%eax 44: 01 c2 add %eax,%edx 46: 8b 45 fc mov -0x4(%rbp),%eax 49: 01 d0 add %edx,%eax 4b: 89 c7 mov %eax,%edi 4d: e8 00 00 00 00 callq 52 &lt;main+0x2e&gt; 52: 8b 45 f8 mov -0x8(%rbp),%eax 55: c9 leaveq 56: c3 retq 代码段Contents of section .text:就是.text的数据以十六进制方式打印出来的内容，共0x57字节。Disassembly of section .text:就是.text的数据的反编译结果。 数据段和只读数据段.data段保存的是那些已经初始化了的全局静态变量和局部静态变量。SimpleSection.c代码里面一共有两个这样的变量，分别是global_init_varabal与static_var。这两个变量每个4个字节，一共刚好8个字节。 我们在调用“printf”的时候，用到了一个字符串常量“%d\\n”，它是一种只读数据，所以它被放到了.rodata段。可以看到.rodata段的4个字节刚好是这个字符串常量的ASCII码，最后以\\0结尾。 BSS段global_uninit_var和static_var2就是被存放在.bss段，其实更准确的说法是.bss段为它们预留了空间。但是我们可以看到该段的大小只有4个字节，这与global_uninit_var和static_var2的大小的8个字节不符。 通过符号表（Symbol Table）看到，只有static_var2被存放在了.bss段，而global_uninit_var却没有被存放在任何段，只是一个未定义的“COMMON符号”（这其实是跟不同的语言与不同的编译器实现有关，有些编译器会将全局的未初始化变量存放在目标文件.bss段，有些则不存放，只是预留一个未定义的全局变量符号，等到最终链接成可执行文件的时候再在.bss段分配空间）。 123456789101112131415161718192021$objdump -x -s -d SimpleSection.o...SYMBOL TABLE:0000000000000000 l df *ABS* 0000000000000000 SimpleSection.c0000000000000000 l d .text 0000000000000000 .text0000000000000000 l d .data 0000000000000000 .data0000000000000000 l d .bss 0000000000000000 .bss0000000000000000 l d .rodata 0000000000000000 .rodata0000000000000004 l O .data 0000000000000004 static_var.18020000000000000000 l O .bss 0000000000000004 static_var2.18030000000000000000 l d .note.GNU-stack 0000000000000000 .note.GNU-stack0000000000000000 l d .eh_frame 0000000000000000 .eh_frame0000000000000000 l d .comment 0000000000000000 .comment0000000000000000 g O .data 0000000000000004 global_init_var0000000000000004 O *COM* 0000000000000004 global_uninit_var0000000000000000 g F .text 0000000000000024 func10000000000000000 *UND* 0000000000000000 _GLOBAL_OFFSET_TABLE_0000000000000000 *UND* 0000000000000000 printf0000000000000024 g F .text 0000000000000033 main... 其他段 段名 说明 .rodata1 Read only Data，只读数据，与..rodata一样 .comment 编译器版本信息，如“.GCC: (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0.” .eh_frame 是一个记录序列，每个记录可以是CIE（Common Information Entry，公共信息条目）或FDE（Frame Description Entry，帧描述条目） .debug 调试信息 .dynamic 动态链接信息 .hash 符号哈希表 .line 调试时的行号表，即源代码行号与编译后指令的对应表 .note 额外的编译器信息，如程序的公司名、发布版本号等 .strtab String Table 字符串表，用于存放ELF文件中用到的各种字符串 .symtab Symbol Table 符号表 .shstrtab Section String Table 段名表 .plt .got 动态链接的跳转表和全局入口表 .init .fini 程序初始化与终结代码段 应用程序也可以自定义段名，但自定义的段名不能使用“.”作为前缀，否则容易跟系统保留段名冲突。另外，GCC提供了一个扩展机制，我们在全局变量或函数之前加上__ attribute__((section(&quot;name&quot;)))属性就可以把相应的变量或函数放到以“name”作为段名的段中。例如 1__attribute__((section(\"FOO\"))) int global = 42; 参考 《程序员的自我修养 –链接、装载与库》","link":"/2019/05/c_code_and_elf_01.html"},{"title":"定时备份网站数据到GitHub的私有库","text":"最近听到许多数据丢失的惨况。那么，如何使用Github备份网站数据（还能看到每次更改、随时回档）？ 在GitHub上创建私有库，例如backups，并git clone到服务器中。 创建备份脚本auto_backup_halo.sh，并chmod +x auto_backup_halo.sh 赋予执行权限。 1234567891011121314151617#!/bin/sh# 导入环境变量. /etc/profile time=`date +%Y%m%d` # 切到本地仓库cd /root/backups# 复制需要备份的文件夹到仓库cp -r /root/.halo/. .halo# git提交git add .git commit -m $timegit push 通过crontab -e将备份脚本添加到定时任务中，加入以下内容。 155 23 * * * /bin/sh /var/auto/auto_backup_halo.sh 通过service crond restart重启crontab服务。 附录crontab的文件格式 第1列 分钟 0～59 第2列 小时 0～23（0表示子夜） 第3列 日 1～31 第4列 月 1～12 第5列 星期 0～7（0和7表示星期天） 第6列 要运行的命令 crontab的环境变量问题crontab总是不会默认从用户profile文件中读取环境变量参数，经常导致在手动执行某个脚本时是成功的，但是到crontab中试图让它定期执行时就是会出错，提示：command not found。三种方法可以解决这个问题，主要是让环境变量在crontab中被定义。 在shell脚本中但凡涉及文件路径时写全局路径。 shell脚本引入环境变量。 123#!/bin/sh. /etc/profile crontab执行命令中加入环境变量。 155 23 * * * . /etc/profile;/bin/sh /var/auto/auto_backup_halo.sh","link":"/2019/02/backup_website_to_github_repo.html"},{"title":"SSH免密码登录和会话管理","text":"这篇教程介绍使用SSH Key来实现SSH无密码登录，以及如何利用config配置文件进行会话管理。 配置ssh免密码登录ssh免密码登录需要使用到公钥和私钥。 这里假设A机想通过ssh免密码登录到B机。一般做法是在A机上生成公钥/私钥对，A机保留自己的私钥，然后将公钥添加到B机中。 首先需要在A机下生成公钥/私钥对，参数：-f 生成的文件名，会在.ssh目录下生成id_rsa和id_rsa.pub。 1ssh-keygen -t rsa -f id_rsa 注：如果命名不为id_rsa，则不会生成在.ssh目录中，就需要手动把id_rsaxxx私钥文件（不带.pub后缀）移动到当前用户的.ssh目录下。 将产生的公钥（xxxxx.pub）复制到B机的用户目录下，可以采用各种方式，以下用scp举例： 1scp xxxxx.pub username@IP:/home/username/xxxxx.pub 将公钥追加到authorzied_keys中，可以通过A机使用密码登录B机（或直接在B机上操作）； 远程登录B机，将xxxxx.pub公钥追加到authorzied_keys中： 12ssh username@IPcat xxxxx.pub &gt;&gt; .ssh/authorized_keys 之后需要重启B机的sshd服务，通过以下命令重启： 1service sshd restart 注：authorzied_keys的权限要是600。如果是服务器，最好把密码登录关闭。 并在A机上测试，如果是默认的文件名，则可以去掉-i参数(用于指定私钥文件位置) 1ssh -i \"私钥文件路径\" user@hostname 利用config进行会话管理多私钥管理SSH利用config管理会话（无需通过命令-i指定私钥、端口等参数登录，尤其当有多个私钥时，管理和操作会变复杂），可以通过在.ssh目录下新建一个config文件来进行管理。 新增ssh的配置文件config，并修改权限； 12touch ~/.ssh/configchmod 600 ~/.ssh/config 常见的配置内容（可配置多个）如下： 12345Host 别名 Hostname 主机名 IdentityFile 私钥路径 Port 端口 User 用户名 之后即可通过ssh 别名登录主机了。 会话保活当你使用ssh命令连接公司服务器时，很有可能会出现闲置一段时间后被服务器自行断开的情况，这可能是运维部门的安全策略。但这种被动的断开很可能会影响到自己的工作上下文。 在config文件增加以下内容，意思为每30秒发送一个no-op包，通过心跳保活。 12Host * ServerAliveInterval 30","link":"/2019/02/ssh_key_and_ssh_config.html"},{"title":"编程科普 - ELF文件结构（二）","text":"ELF文件结构中其他重要的部分，比如ELF文件头、段表、重定位表和字符串表等。 ELF文件头ELF文件头（ELF Header）包含了描述整个文件的基本属性，比如ELF文件版本、目标机器型号、程序入口地址等。可以用readelf命令来详细查看ELF文件。 123456789101112131415161718192021$readelf -h SimpleSection.oELF Header: Magic: 7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00 Class: ELF64 Data: 2's complement, little endian Version: 1 (current) OS/ABI: UNIX - System V ABI Version: 0 Type: REL (Relocatable file) Machine: Advanced Micro Devices X86-64 Version: 0x1 Entry point address: 0x0 Start of program headers: 0 (bytes into file) Start of section headers: 1104 (bytes into file) Flags: 0x0 Size of this header: 64 (bytes) Size of program headers: 0 (bytes) Number of program headers: 0 Size of section headers: 64 (bytes) Number of section headers: 13 Section header string table index: 12 从上面输出的结果可以看到，ELF的文件头中定义了ELF魔数、文件机器字节长度、数据存储方式、版本、运行平台、ABI版本、ELF重定位类型、硬件平台、硬件平台版本、入口地址、程序头入口和长度、段表的位置和长度及段的数量等。 ELF文件头结构及相关常数被定义在/usr/include/elf.h里，因为ELF文件在各种平台下都通用。ELF文件有32位版本和64位版本，所以它的文件头结构也有Elf32_Ehdr和Elf64_Ehdr两种版本。它们的成员种类是一样的，只不过有些成员的大小不一样。为了对每个成员的大小做出明确的规定以便于在不同的编译环境下都拥有相同的字段长度，“elf.h”定义了一套自己的变量体系。 1234567891011121314151617181920212223/* Type for a 16-bit quantity. */typedef uint16_t Elf32_Half;typedef uint16_t Elf64_Half;/* Types for signed and unsigned 32-bit quantities. */typedef uint32_t Elf32_Word;typedef int32_t Elf32_Sword;typedef uint32_t Elf64_Word;typedef int32_t Elf64_Sword;/* Types for signed and unsigned 64-bit quantities. */typedef uint64_t Elf32_Xword;typedef int64_t Elf32_Sxword;typedef uint64_t Elf64_Xword;typedef int64_t Elf64_Sxword;/* Type of addresses. */typedef uint32_t Elf32_Addr;typedef uint64_t Elf64_Addr;/* Type of file offsets. */typedef uint32_t Elf32_Off;typedef uint64_t Elf64_Off; 以64位版本Elf64_Ehdr为例，其结构为 12345678910111213141516171819#define EI_NIDENT (16)typedef struct{ unsigned char e_ident[EI_NIDENT]; /* 魔数与其他内容 */ Elf64_Half e_type; /* 文件类型 */ Elf64_Half e_machine; /* 目标CPU体系结构 */ Elf64_Word e_version; /* 文件版本 */ Elf64_Addr e_entry; /* 程序入口地址 */ Elf64_Off e_phoff; /* 程序头的偏移量 */ Elf64_Off e_shoff; /* 段表在文件中的偏移量 */ Elf64_Word e_flags; /* 特定于处理器的标志 */ Elf64_Half e_ehsize; /* 文件头大小 */ Elf64_Half e_phentsize; /* 程序头中每个结构的大小 */ Elf64_Half e_phnum; /* 程序头中有多少个结构 */ Elf64_Half e_shentsize; /* 段表中每个结构的大小 */ Elf64_Half e_shnum; /* 段表中有多少个结构，也就是有多少段 */ Elf64_Half e_shstrndx; /* 段表字符串表在段表中的下标 */} Elf64_Ehdr; 从这里可以看出ELF文件头结构跟前面readelf输出的ELF文件头信息一一对应。其中e_ident的内容，对应Magic、Class、Data、Version、OS/ABI、ABI Version。 前4个字节为文件魔数，对应DEL、E、L、F的ASCII码。很多文件的魔数由来都有它的历史背景，就如同“马屁股决定航天飞机”的故事。 这里不详细介绍所有的结构体成员。e_type指明了文件类型，就如之前介绍的可重定位文件、可执行文件、共享目标文件等。 1234567/* Legal values for e_type (object file type). */...#define ET_REL 1 /* 可重定位文件 */#define ET_EXEC 2 /* 可执行文件 */#define ET_DYN 3 /* 共享目标文件 */#define ET_CORE 4 /* Core文件 */... 段表段表（Section Header Table）就是保存这些段的基本属性的结构。段表是ELF文件中除了文件头以外最重要的结构，它描述了ELF的各个段的信息，比如每个段的段名、段的长度、在文件中的偏移、读写权限及段的其他属性。也就是说，ELF文件的段结构就是由段表决定的，编译器、链接器和装载器都是依靠段表来定位和访问各个段的属性的。段表在ELF文件中的位置由ELF文件头的e_shoff成员决定，即1104（0x450）。 objdump -h命令只能显示了ELF文件中关键的段，使用readelf工具来查看ELF文件真正的段结构。 12345678910111213141516171819202122232425262728293031323334353637$readelf -S SimpleSection.oThere are 13 section headers, starting at offset 0x450:Section Headers: [Nr] Name Type Address Offset Size EntSize Flags Link Info Align [ 0] NULL 0000000000000000 00000000 0000000000000000 0000000000000000 0 0 0 [ 1] .text PROGBITS 0000000000000000 00000040 0000000000000057 0000000000000000 AX 0 0 1 [ 2] .rela.text RELA 0000000000000000 00000340 0000000000000078 0000000000000018 I 10 1 8 [ 3] .data PROGBITS 0000000000000000 00000098 0000000000000008 0000000000000000 WA 0 0 4 [ 4] .bss NOBITS 0000000000000000 000000a0 0000000000000004 0000000000000000 WA 0 0 4 [ 5] .rodata PROGBITS 0000000000000000 000000a0 0000000000000004 0000000000000000 A 0 0 1 [ 6] .comment PROGBITS 0000000000000000 000000a4 000000000000002c 0000000000000001 MS 0 0 1 [ 7] .note.GNU-stack PROGBITS 0000000000000000 000000d0 0000000000000000 0000000000000000 0 0 1 [ 8] .eh_frame PROGBITS 0000000000000000 000000d0 0000000000000058 0000000000000000 A 0 0 8 [ 9] .rela.eh_frame RELA 0000000000000000 000003b8 0000000000000030 0000000000000018 I 10 8 8 [10] .symtab SYMTAB 0000000000000000 00000128 0000000000000198 0000000000000018 11 11 8 [11] .strtab STRTAB 0000000000000000 000002c0 000000000000007c 0000000000000000 0 0 1 [12] .shstrtab STRTAB 0000000000000000 000003e8 0000000000000061 0000000000000000 0 0 1Key to Flags: W (write), A (alloc), X (execute), M (merge), S (strings), I (info), L (link order), O (extra OS processing required), G (group), T (TLS), C (compressed), x (unknown), o (OS specific), E (exclude), l (large), p (processor specific) 对于SimpleSection.o来说，段表是有13个元素的数组。ELF段表的这个数组的第1个元素是无效的段描述符，它的类型为NULL，除此之外每个段描述符都对应一个段，也就是说共有12个有效的段。其中，段描述符的结构为 12345678910111213typedef struct{ Elf64_Word sh_name; /* 段名 (段名字符串在.shstrtab中的偏移) */ Elf64_Word sh_type; /* 段的类型 */ Elf64_Xword sh_flags; /* 段的标志位 */ Elf64_Addr sh_addr; /* 段虚拟地址 */ Elf64_Off sh_offset; /* 该段在文件中的偏移 */ Elf64_Xword sh_size; /* 段的长度 */ Elf64_Word sh_link; /* 段的链接信息 */ Elf64_Word sh_info; /* 段的链接信息 */ Elf64_Xword sh_addralign; /* 段地址对齐 */ Elf64_Xword sh_entsize; /* 项的长度，一些段中会包含固定长度的项 */} Elf64_Shdr; 段的名字只是在链接和编译过程中有意义，但它不能真正地表示段的类型。我们也可以将一个数据段命名为“.text”，对于编译器和链接器来说，主要决定段的属性的是段的类型（sh_type）和段的标志位（sh_flags）。 段的类型（sh_type）： 123456789#define SHT_NULL 0 /* Section header table entry unused */#define SHT_PROGBITS 1 /* Program data */#define SHT_SYMTAB 2 /* Symbol table */#define SHT_STRTAB 3 /* String table */#define SHT_RELA 4 /* Relocation entries with addends */#define SHT_HASH 5 /* Symbol hash table */#define SHT_DYNAMIC 6 /* Dynamic linking information */#define SHT_NOTE 7 /* Notes */... 段的标志位（sh_flags）：表示该段在进程虚拟地址空间中的属性，比如是否可写，是否可执行等。 1234#define SHF_WRITE (1 &lt;&lt; 0) /* Writable */#define SHF_ALLOC (1 &lt;&lt; 1) /* Occupies memory during execution */#define SHF_EXECINSTR (1 &lt;&lt; 2) /* Executable */#define SHF_MERGE (1 &lt;&lt; 4) /* Might be merged */ 段的链接信息（sh_link 、 sh_info）：如果段的类型是与链接相关的（不论是动态链接或静态链接），比如重定位表、符号表等；对于其他类型的段，这两个成员没有意义。 重定位表SimpleSection.o中有一个叫做.rela.text的段，它的类型（sh_type）为SHT_RELA，也就是说它是一个重定位表（Relocation Table）。链接器在处理目标文件时，须要对目标文件中某些部位进行重定位，即代码段和数据段中那些对绝对地址的引用的位置。这些重定位的信息都记录在ELF文件的重定位表里面，对于每个须要重定位的代码段或数据段，都会有一个相应的重定位表。.rela.text就是针对.text段的重定位表，因为.text段中至少有一个绝对地址的引用（即对printf函数的调用）。 重定位表的sh_link表示符号表的下标，sh_info表示它作用于哪个段。比如.rela.text作用于.text段（.text段的下标为1），那么.rel.text的sh_info为1。 字符串表ELF文件中用到了很多字符串，比如段名、变量名等。因为字符串的长度往往是不定的，所以用固定的结构来表示它比较困难。一种很不错的做法是把字符串集中起来存放到一个表，然后使用字符串在表中的偏移来引用字符串，如下所示。 通过这种方法，在ELF文件中引用字符串只须给出一个数字下标即可。字符串表在ELF文件中也以段的形式保存，常见为.strtab字符串表（String Table）或.shstrtab段表字符串表（Section Header String Table）。 参考 《程序员的自我修养 –链接、装载与库》","link":"/2019/05/c_code_and_elf_02.html"},{"title":"Git仓库删除全部历史提交","text":"在Git仓库的历史记录中可能存在敏感信息，也可能存在已删除大文件（仍会占据空间）。如何删除这些历史记录，形成一个全新的仓库，并且保持代码不变呢？ 具体操作这里利用了分支操作来清空历史提交记录，首先新建一个分支latest_branch，添加所有文件，完成第一次提交，然后删除主分支master，最后将latest_branch重命名为master后完成远程仓库的更新。这样，master分支中只剩下一条提交记录。 123456789101112# 1.Checkoutgit checkout --orphan latest_branch# 2. Add all the filesgit add -A# 3. Commit the changesgit commit -am \"init\"# 4. Delete the branchgit branch -D master# 5.Rename the current branch to mastergit branch -m master# 6.Finally, force update your repositorygit push -f origin master","link":"/2019/02/github_repo_remove_all_commit.html"},{"title":"利用Github仓库提供的webhook完成hexo博客的自动化部署","text":"使用webhook来完成hexo博客的自动化部署，本文提供一个Docker容器的解决方案。从此不必再进行多次的重复劳动，让博客网站实现自动更新。 什么是webhook?webhook简单来说就是“用户定义的HTTP回调”。webhook通常会被某些事件激活，比如将代码推送到仓库或评论博客等事件。当这类事件发生时，提供webhook功能的网站将向在webhook中配置的URL发送HTTP请求，从而触发另一个网站的行为。 为了加深理解，我们以github仓库提供的webhook功能做讲解。在github仓库的settings选项中，我们可以配置webhooks。这里的Payload URL就是webhook将会回调的URL，即当事件触发的时候会向这个URL发生请求。下面的红框内容为触发webhook的事件，我这里选择了仓库有push操作发生。 一句话来说，当我push内容到仓库时，github将会向https://ultraji.xyz/webhook/deploy发生请求。 如何利用webhook来部署自己的博客自己制作的话，大致需要以下两个东西（文章末尾提供了Docker容器）： 等待接受webhook发来请求的微服务，用go实现 由微服务触发的服务器动作，即部署博客，用Shell脚本实现 接受webhook发来请求的微服务在这里，我使用Go语言来编写微服务webhook.go，刚学的Go，写的可能惨不忍睹。 sign验证的意义为何？如果有不怀好意的人一直访问这个微服务，那么你的网站就会不断地更新。那么如何判断是对的人发送的请求，故sign验证必不可少。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768package mainimport ( \"flag\" \"fmt\" \"strings\" \"os/exec\" \"io/ioutil\" \"net/http\" \"crypto/sha1\" \"crypto/hmac\" \"github.com/gin-gonic/gin\")func genSign(key string, data string) string { h_key := []byte(key) mac := hmac.New(sha1.New, h_key) mac.Write([]byte(data)) return fmt.Sprintf(\"%x\", mac.Sum(nil))}func main() { /* 获取命令行Secret参数 */ var secret string flag.StringVar(&amp;secret, \"p\", \"123456\", \"default secret is 123456\") flag.Parse() gin.SetMode(gin.ReleaseMode) router := gin.Default() /* 仅用于测试请求是否正常访问 */ router.GET(\"/\", func(c *gin.Context) { c.String(http.StatusOK, \"Service For GitHub Webhook!\") }) /* 接收webhook请求 */ router.POST(\"/deploy\", func(c *gin.Context) { /* 获取请求头信息 */ x_Event := c.Request.Header.Get(\"X-GitHub-Event\") x_Signature := c.Request.Header.Get(\"X-Hub-Signature\") /* 获取sign */ x_sign := strings.Split(x_Signature, \"=\")[1] /* 获取Body */ req_body, _ := ioutil.ReadAll(c.Request.Body) req_str := string(req_body) my_sign := genSign(secret, req_str) /* 生成本地Sign */ if x_sign == my_sign { /* sign 验证成功 */ if x_Event == \"push\" { /* 如有需要，可以从body中获取想要的参数，方法如下: */ // cmt_ref := gjson.Get(req_str,\"ref\") /* 执行Shell脚本 */ _, err := exec.Command(\"sh\",\"/app/deploy.sh\").Output() if err != nil { fmt.Println(err) } c.JSON(http.StatusOK, \"Success\") } else { c.JSON(http.StatusOK, \"Just Support Push Event\") } } else { c.JSON(http.StatusOK, \"Sign Error\") } }) router.Run(\":8000\")} 用Shell脚本实现博客部署即在上面代码中看到的deploy.sh，即为部署博客的脚本。因为是hexo静态博客，部署脚本的实现也非常简单。如果不存在仓库，就git clone；若存在就git pull。 12345678910111213141516171819202122232425262728#!/bin/shSITE_PATH='/app/hexo'CLONE_URL=${CLONE_URL:-\"\"}USER_NAME=${USER_NAME:-\"\"}USER_TOKEN=${USER_TOKEN:-\"\"}URL_SCHEME=\"https://\"if [ \"$CLONE_URL\" == \"\" ]; then echo \"CLONE_URL is empty!\" exit 1fiif [ ! -d \"$SITE_PATH/.git\" ]; then mkdir -p $SITE_PATH if [ \"$USER_NAME\" != \"\" ] &amp;&amp; [ \"$USER_TOKEN\" != \"\" ]; then echo \"Private repo!\" # private repo git clone ${URL_SCHEME}${USER_NAME}\":\"${USER_TOKEN}\"@\"${CLONE_URL##*//} $SITE_PATH else echo \"Public repo!\" # public repo git clone ${CLONE_URL} $SITE_PATH fificd $SITE_PATHgit clean -fgit pullecho '[SUCC]: Success!' Docker容器的解决方法首先确保你的服务器安装了docker以及docker-compose，如何安装不在赘述。安装教程可参考利用Lychee快速搭建个人图床 首先git clone项目到服务器后台； 12git clone git@github.com:ultraji/dockerfiles.gitcd dockerfiles/hexo-webhook/ 修改docker-compose.yaml，根据自身情况填写好environment； 123456environment: - CLONE_URL= # 仓库地址的完整地址 - WEBHOOK_SECURT= # github settings中自己设置的secert # 私有仓库需要以下两项内容 # - USER_NAME= # - USER_TOKEN= 构建镜像和部署； 12docker-compose builddocker-compose up -d 部署完成后，访问http://IP:8100即可访问hexo博客，http://IP:8100/webhook/deploy即为webhook回调地址（如需nginx反向代理，请自行配置）。","link":"/2019/02/github_repo_webhook_hexo.html"},{"title":"善用佳软 - Windows篇","text":"工欲善其事，必先利其器。好软件何其多，找到适合自己的却十分不易，反反复复地装了卸，卸了装。以下推荐的是我个人认为非常好用的。 下载工具 - Internet Download Manager下载工具存在的意义在何，我只想要更快的下载速度。个人没有太多P2P下载需求，然后Chrome自带的下载器又超级不好用。emmmm……太好用了，以至于买了正版。 工具：Internet Download Manager 官网：https://www.internetdownloadmanager.com/ 平台：Windows 收费方式：一年付费/终生付费 功能： 支持断点续传； 免打扰（静默下载）； 下载任意内容（多浏览器支持，视频音频下载，网盘下载，准确识别文件名，网页嗅探）； 自动化（队列功能，命令行参数）； 下载管理； 不足： IDM功能专一，是纯正的HTTP，FTP等基础文件协议下载工具，不支持P2P方式(bt，emule等)； 自带的界面太丑，但是可以自定义； 只支持Windows； 软件界面： 笔记工具 - Notion这估计是我用的最后一个笔记工具（Flag立起来）。尝试过印象笔记，有道云笔记，OneNote等，都不是很适合我。Notion 是一款将笔记、知识库和任务管理整合的协作工具。 工具：Notion 官网：https://www.notion.so/ 平台：Windows/Mac/iOS/Android 收费方式：免费/付费订阅 优势： 平台不是障碍，因为它还支持web； 对于绝大部分用户，免费功能就足够用了； 超强的网页支持，在Pages中可以直接嵌入网页，添加URL还可以创建缩略的书签等； 动态性（Media、Embeds、Advenced模块都是动态的，你可以往编辑器里直接放一个视频、放Google地图、放一个自定义模板。然后在编辑器里点击它们、与它们交互）； 支持导入（5种格式：TXT、Markdown、CSV（Excel）、Word、HTML；7种服务：Trello、Asana、Google Docs、Dropbox Paper、Quip、Evernote、Workflowy），导出（可以导出成MarkDown，PDF，Html） … 不足： 不能定义自己喜欢的渲染； 英文的哦，没有中文版； 上手需要一点练习； 软件界面： 阅读软件 - CalibreCalibre的功能非常强大且全面，提供“一站式”的电子书解决方案。而且它是完全免费、开源的。 工具：Calibre 官网：https://calibre-ebook.com 平台：Windows/Mac/Linux 收费方式：免费 优势： 支持邮箱推送数据 支持电子书格式转换 一站式解决方案 … 不足： 体积庞大、速度慢、BUG较多 软件界面： 截图工具 - SnipasteSnipaste 是一个简单但强大的截图工具，也可以让你将截图贴回到屏幕上！下载并打开Snipaste，按下F1来开始截图，再按F3，截图就在桌面置顶显示了。就这么简单！ 工具：Snipaste 官网：https://zh.snipaste.com/ 平台：Windows/Mac 收费方式：免费 优势： 简单强大，免费但无广告 软件界面： 桌面管理 - Fences买的第一款正版软件，定价也很良心。桌面本该如此干净。 工具：Fences 官网：https://www.stardock.com/products/fences/ 平台：Windows 软件截图： 远程控制 - Teamviewer需要我远程协助的小伙伴，我都“强制”让他们先装了Teamviewer。 工具：Teamviewer 官网：https://www.teamviewer.com/ 平台：Windows/Mac/Linux/Android/iOS/… 收费方式：个人用途免费 软件截图： 实用工具 - Dism++其实我们都是一些强迫症晚期患者，只想要找个轻巧、好使、透明、不流氓、不装可怜、不唠唠叨叨的实用工具。不过找了半天没找到，但是我们没有放弃治疗，用自己的双手初步实现了梦想，联手打造Dism++——一个不为利益、不跟风、不做作、单纯为执着与激情而生的小工具。安得广厦千万间，大庇天下寒士俱欢颜！ – 摘自官网 工具：Dism++ 官网：https://www.chuyu.me 平台：Windows 收费方式：免费开源 优势： 功能强大，实用，简单 软件截图： 压缩工具 7-zip7-Zip是一款完全免费而且开源的压缩软件，相比其他软件有更高的压缩比但同时耗费的资源也相对更多，如果你需要一款能够提供强大压缩性能的软件，那么它是你最好的选择。 工具：7-zip 官网：https://www.7-zip.org/ 平台：Windows 收费方式：免费 优势： 压缩速度快，压缩率高，占用资源少，安装包大小才1M。","link":"/2019/01/windows_app_recommend.html"},{"title":"利用Lychee快速搭建个人图床","text":"简单说，图床就是一个在网络上存储图片的地方。Lychee是一款开源的图片管理系统，实际上也可以用作图床。 为什么自建图床国内的博客平台比较多，目前也没找到比较好用的多平台部署工具。而要在多平台部署博客，那么就需要有一个稳定图片外链，否则就得把图片上次到每个平台上，即耗时又耗力。 国外图床说被ban就被ban，国内图床很多都不稳定，所以就有很多文章中的图片经常无法打开。其实，目前也存在很多稳定的第三方图床，例如七牛云、又拍云、SM.MS、聚合图床等（这里不比较各类图床）。当然，还可以使用付费的OSS，例如阿里云、腾讯云等。 快速搭建图床当然首先你得要有一个可用的服务器，也不推荐不熟悉服务器操作的人使用lnmp的方式来搭建Lychee图床，故这里推荐使用docker-compose方式进行部署。 我的配置如下： 一台装有centos7的阿里云服务器 接下来将以最简单的方式来完成所有操作。 一、首先安装 Docker如果碰到某些工具（例如curl）没有安装，请自行安装。 12345678# 1.安装dockercurl -fsSL https://get.docker.com -o get-docker.shsudo sh get-docker.sh# 2.启动docker进程sudo systemctl start docker# 3.验证sudo docker run hello-worlddocker ps 二、安装docker-compose如果碰到问题，请查阅官方安装步骤的注意细节（Note）。 12sudo curl -L \"https://github.com/docker/compose/releases/download/1.24.1/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-composesudo chmod +x /usr/local/bin/docker-compose 三、构建镜像官方Github仓库：https://github.com/electerious/Lychee 官方文档在Docker章节给出了推荐的dockers镜像，根据它给出的镜像编写如下docker-compose.yaml。 12345678910111213141516version: &quot;2&quot;services: lychee: image: kdelfour/lychee-docker container_name: lychee environment: - PUID=1000 - PGID=1000 - TZ=Asia/Shanghai volumes: - /www/lychee/uploads:/uploads/ - /www/lychee/data:/data/ - /www/lychee/mysql:/mysql/ ports: - 8080:80 restart: unless-stopped 或者自行构建镜像 1234git clone https://github.com/ultraji/dockerfilescd dockerfiles/lycheedocker-compose builddocker-compose up -d 这里需要放开服务器上对应文件夹uploads，data的权限。 12# 在/www/lychee中执行chmod -R 777 uploads/ data/ 这里的8080端口为对外端口（可以自行修改）。此时你可以通过http://ip:port访问图床了（记得打开服务器相应端口，这里也不讲解nginx操作）。 四、完成网页端配置登录网页后，首先完成数据库配置，该镜像已经设置了默认的数据库信息，如下： url : localhost database name : lychee user name : lychee user password : lychee 创建用户： 之后，你就可以使用lychee图片管理系统了。 注：如果出现无法上传图片的情况，请重新确认uploads/，data/文件夹及子文件夹的权限。","link":"/2019/02/use_lychee_for_image_upload.html"},{"title":"黑苹果折腾记","text":"一直想自己动手组一个台式机，同时突发奇想，想体验一下苹果系统，于是，有了这片博文。预算7500，结果超了预算300块，还能接受吧。 粗暴地展示一下配置 配置 型号 CPU i7-9700k 主板 Gigabyte Z390 I AORUS PRO WIFI 内存 海盗船ddr4 3000 16G 硬盘 三星970 EVO 500G (For Win) 硬盘 三星860 EVO 500G (For Mac) 显卡 蓝宝石 RX580 8G极光版（2304sp） 网卡 BCM943602CS + m2 ssd转接板 电源 海盗船rm650x 散热 安钛克海王星240ARGB水冷 机箱 追风者215ptg 在选择主板时，选了技嘉主板，喜欢这牌子，且便宜嘛，唯一没仔细研究的配件，于是碰到了一个大坑。 值得吐槽的装机装机真是一件费力费时费脑的事，研究了好久的布线，拆了装，装了拆。不得不说，现在的主板对小白真的是非常友善，能看到的很多接口都做了防呆设计。有些接口不能确定，不懂靠度娘（我常常自嘲的碰瓷式学习法）。 装机过程相对还是比较顺利的。唯一出问题的就是买的网卡，在插网卡时，唉～，我的转接板两个凹槽，主板上的接口只有1个凸起，后来才学习到了，m2接口是m2接口，没毛病，但也有类型啊，我要的是m2 NVMe ssd接口，结果买成了m2 ngff接口的转接板。之后联系了商家，感谢商家原谅无知的我，退货换成了m2 NVMe ssd接口的转接板。 第一次觉得，按开机键原来是一件很有压力的事。可喜可贺的是，我这个小白第一次装机的结果还是顺利的，一次就点亮了BIOS。 一切为了安全为了保险起见，检查各个硬件的状态，当然先装个win10来检测一下了。当然装系统已经是一件没太大技术含量的体力活了。尤其是在微软官网提供Windows 10介质创建工具之后，只要有一个U盘，人人都能装系统。 emmm…安装完所有驱动后，检查了一下设备管理器，一切ok，这感觉真棒（当然不可避免的是，装了娱乐大使，愉快地跑了波分，轻薄笔记本用惯了，看到300fps的显卡测试的时候，还有有点小惊讶的，毕竟是一张普通的显卡）。 重头戏当然是黑苹果虽然装惯了windows和ubuntu，但毕竟是第一次装hackintosh，约莫着研究了四五篇博文后，感觉讲的都不一样，还是直接动手吧，反正我是独立的硬盘安装mac，不怕把装好的windows弄坏。 又是为了安全，本能告诉我，先在硬盘上分一个efi分区，后来验证没毛病。镜像用了黑果小兵的镜像，感谢黑果小兵等大佬的摸索，提供了很好的中文资料，不需要去生啃英文博文。 不愧是大佬封装的镜像，插上U盘傻瓜式一步一步地点下来，没想到黑苹果装起来比ubuntu还简单。 然后看到很多文章说，这样装完后黑苹果是启动不了的，试了一下果然如此。再一次感谢本能，解决方法就是把U盘中的EFI文件夹整个拷到硬盘的efi分区中。 emmmm…真香。由于我配置硬件时都是按免驱标准配置的，进入系统后，绝大部分硬件都是正常工作的。剩下出问题的就是没声音和蓝牙冲突。简单研究了一下AppleALC，成功把声音给弄出来了。 装黑苹果碰到的大坑问题1在选择主板时，选了技嘉主板，便宜嘛，于是碰到了一个大坑。技嘉z390i主板的板载网卡接口为cnvi接口，不支持更换为黑苹果的网卡（网传，华擎和华硕的主板可直接更换板载网卡），pcie又拿来插显卡了，实在没位置。 解决方案：牺牲一个m2接口，用来插网卡，可以购买淘宝现成的方案（无线网卡+转接板的方式）。 问题2技嘉主板z390i自带蓝牙和wifi，且技嘉bios中无法关闭蓝牙。故在使用BCM943602CS时，会与板载蓝牙发生冲突，故需要屏蔽板载蓝牙。 强迫症的我不想拆掉主板上的板载蓝牙和wifi模块，为了解决这个问题，翻了很多博文，中文搜完，英文搜，英文搜完，中文搜。中途放弃，在淘宝上找了3家安装黑苹果的店定制屏蔽板载蓝牙功能，付了3次款，退了3次款。答复：抱歉，解决不了。麻烦亲退款。你们明明宣传说，有几十人专家技术团队，高效可靠。。。 最后，总算在远景论坛一位小哥的评论中找到了方向。 解决方案： 物理方式：拆除板载蓝牙和wifi模块（简单粗暴真实有效）。 软件方式：可在Hackintool中查看，定制屏蔽对应USB口（一般连接速度为12Mbps，我的端口为14）。 装完之后，当然airdrop也是ok的。真棒。 mac和2k显示器不得不说的尴尬事我的联想t24h显示器很早之前就买了，有感情了，不想换（PS：其实是没钱）。在2k分辨率下，mac是不支持HiDPI，导致字体很小，看起来很不舒服。看了很多文章，改这个改那个的，哇，好麻烦，我这个人又这么懒。本着没有什么脚本是github上找不到的想法，还真找到了一款傻瓜式脚本one-key-hidpi。最喜欢这种一行代码的事了（当然需要在关闭系统完整性保护SIP情况下执行）。 1bash -c \"$(curl -fsSL https://raw.githubusercontent.com/xzhih/one-key-hidpi/master/hidpi.sh)\" 附录最后，本来没想RGB的，结果自带RGB，那么就喊一句”RGB万岁”。 记，第一篇在mac下写的博文。等我有钱买得起mac了，乔老爷，我会支持您的正版事业的。","link":"/2019/11/make_hackintosh.html"},{"title":"ubuntu使用snap安装下载慢","text":"Snap是Canonical公司推出的新型软件打包方式，但是因为一直没有国内镜像源的关系，下载速度极慢，让国内用户苦不堪言。 方式一、直接下载对应snap包 前往https://uappexplorer.com/snaps搜索需要的snap包， 例如mailspring 下载对应架构的snap包，在同一目录执行以下命令即可 1sudo snap install xxx.snap --dangerous 方式二、使用代理来加速由于无法直接设置上http_proxy环境变量，但我们可以为snapd直接设置proxy。snapd会读取/etc/environment中的变量，因此在这里的代理服务器环境变量能够生效。 1234567891011121314# 前置操作, 修改systemctl edit使用的编辑器为vim, 如果不介意使用nano可以跳过这一步sudo echo \"export SYSTEMD_EDITOR=\\\"/bin/vim\\\" \" &gt;&gt; /etc/profilesource /etc/profile# 设置代理（根据自己的代理配置进行填写）sudo systemctl edit snapd# 加上：[Service]Environment=\"http_proxy=http://127.0.0.1:port\"Environment=\"https_proxy=http://127.0.0.1:port\"# 保存退出sudo systemctl daemon-reloadsudo systemctl restart snapd","link":"/2019/02/snap_install_too_slow.html"},{"title":"善用佳软 - Chrome插件篇","text":"推荐个人认为挺好用的一些Chrome扩展。 Infinity 新标签页 Chrome商店：Infinity 新标签页 介绍：一款新标签页插件，致力于创造真正高效优雅的极简生活，自由添加网站图标，云端高清壁纸，快速访问书签、天气、笔记、待办事项、扩展管理与历史记录等，云端同步，完全免费，让你高效且优雅地使用chrome。 Fair AdBlocker Chrome商店：Fair AdBlocker 介绍：广告屏蔽哪家强，…… Video Speed Controller Chrome商店：Video Speed Controller 介绍：Video Speed Controller 是一个专门用来为视频添加倍速播放、快进10秒、回放10秒功能的 Chrome、Firefox 扩展，支持从 0.07 倍到 16 倍的速度播放。快进 10 秒很适合那些没有快进功能的小视频网站啊。支持优酷、腾讯视频、B站、爱奇艺等国内HTML5播放器视频。 Octotree Chrome商店：Octotree 介绍：Octotree是一款可以使你在github查看项目时可以清晰明了的看到项目的结构以及具体代码，使下载代码更具有目的性，减少不必要代码的下载的chrome扩展程序。安装这个插件后，打开github项目主页你就可以在左侧看到该项目的文件树，点击对应的文件就可以直接跳转到相应的页面，非常方便。","link":"/2019/01/chrome_plugin_recommend.html"},{"title":"配置Nginx反向代理noVNC（WebSocket）","text":"为什么nginx配置noVNC的代理和其他代理配置会不同呢？什么是WebSocket？ 最近在自己的服务器中运行了一个Docker容器运行novnc服务，对外开放的端口为6080。通过6080端口可以直接访问noVNC服务，而我在Nginx中用常规的方式反向代理了noVNC，却始终访问不通。 为什么noVNC的配置会不一样？这里我们需要理解两个概念：什么是WebSocket以及noVNC的实现原理。 什么是WebSocketWebSocket是一种网络传输协议，可在单个TCP连接上进行全双工通信，位于OSI模型的应用层。WebSocket使得客户端和服务器之间的数据交换变得更加简单，允许服务端主动向客户端推送数据。在WebSocket API中，浏览器和服务器只需要完成一次握手，两者之间就可以创建持久性的连接，并进行双向数据传输。 WebSocket是一种与HTTP不同的协议。 虽然它们不同，但RFC 6455规定：“WebSocket设计为通过80和443端口工作，以及支持HTTP代理和中介”，从而使其与HTTP协议兼容。为了实现兼容性，WebSocket握手使用HTTP Upgrade头从HTTP协议更改为WebSocket协议。 noVNC的实现原理noVNC简单来说就是一个使用HTML5实现的VNC客户端，采用HTML5 WebSockets，Canvas和JavaScript实现，被普遍用在各大云计算、虚拟机控制面板中。noVNC提供一种在网页上通过html5的Canvas，访问机器上vncserver提供的vnc服务，需要做tcp到websocket的转化，才能在html5中显示出来。网页实际上就是一个客户端，类似win下面的vncviewer，只不过填的不是裸露的vnc服务的ip+port，而是由noVNC提供的websockets的代理（noVNC提供一个标识，去反向代理所配置的vnc服务）。总结就是我们访问的是noVNC提供的websockets的代理。 代理noVNC就是要处理好WebSocket代理noVNC就是要处理好WebSocket，就是处理好协议切换（从HTTP/1.1转换为WebSocket），故需要使用HTTP/1.1中提供的协议切换机制。 然而“Upgrade”是一个逐跳的头，它不会从客户端传递到代理服务器。使用正向代理，客户可以使用该CONNECT方法来规避这个问题。但是，这不适用于Nginx反向代理，因为客户端不知道任何代理服务器，所以需要在代理服务器上进行特殊处理。 从版本1.3.13开始，nginx实现了特殊的操作模式，如果代理服务器返回了代码101（交换协议）的响应，客户端和代理服务器之间建立隧道，客户端通过请求中的“Upgrade”请求头。 如上所述，包括“Upgrade”和“Connection”的逐跳Header不会从客户端传递到代理服务器，因此为了让代理服务器知道客户端将协议切换到WebSocket的意图，这些Header必须明确地通过： 12345678910111213141516171819202122http { # map 必须项 map $http_upgrade $connection_upgrade { default upgrade; '' close; } ... server { listen 80; # 修改监听的端口 server_name _; location / { proxy_pass http://127.0.0.1:6080/; # 修改为需要被反向代理的WebSocket的IP和端口，即noNVC的IP和端口 # 以下三项 必须项 proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; } }}","link":"/2019/02/configure_nginx_for_novnc.html"},{"title":"Redis5.0源码 - 数据结构 - 简单动态字符串","text":"在Redis中，没有直接使用C语言传统的字符串表示（以’\\0’结尾的字符数组）， 而是自己构建了一种名为简单动态字符串（simple dynamic string，SDS）的抽象类型，并将SDS用作Redis的默认字符串表示。 设计 相关文件：sds.h、sds.c 首先，sds被定义char*，sds的设计者希望sds不仅作为一个动态字符串使用，同时sds也应该兼容C类型的字符串操作。 1typedef char *sds; 某种类型sds header（不同类型的SDS仅最大存储字节数有区别）如下定义： 123456struct __attribute__ ((__packed__)) sdshdr8 { uint8_t len; /* used */ uint8_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];}; 设计SDS Header时加入： len：用于表示当前SDS已经使用空间的字节数。len的加入，可以使获取长度函数所需的时间复杂度降低到常数级复杂度O(1)。另外，还能保证二进制安全（binary-safe），不会像C语言字符串一样，因为字符串中间出现的’\\0’而提前结束，能保证读取指定len长度的数据。SDS可以拿来存储任意类型的二进制。 alloc：用于表示当前SDS对象申请了多少的空间用于存储字符串（不包含头和’\\0’）。例如buf申请了（20+1位’\\0’）字节的空间，则alloc为20。 flags：低3位用于表示当前SDS的类型，高5位保留。 buf[]：灵活数组类型是C99引入的语言特性。即在struct数据类型的最后一个数据成员，可以为一个未指明长度的数组类型。 注1：例如sds s; ...，s默认指向buf[]成员的位置。 注2：__attribute__ ((__packed__))的作用就是告诉编译器取消结构在编译过程中的优化对齐，按照实际占用字节数进行对齐（默认会进行字节对齐，并填充空字节）。 注3：另外，SDS会在保存的数据末尾自动设置’\\0’空字符，这样在做某些字符串比较时，可以直接使用C语言中的字符串比较函数。 常用API 函数 作用 sdsnew 创建一个包含C字符串init的SDS，通过调用sdsnewlen(init, initlen)实现，创建的SDS的alloc和len均为initlen sdsempty 创建一个不包含的SDS，通过调用sdsnewlen(&quot;&quot;, 0)实现 sdsdup 创建一个给定sds的副本（copy操作），通过调用sdsnewlen(s, sdslen(s))实现 sdsfree 释放指定的SDS(释放所占用的内存空间) sdslen 返回SDS的已使用空间字节数，即len sdsavaid 返回SDS的未使用空间字节数，即alloc-len sdsgrowzero 用空字符将SDS扩展到给定长度 sdscat 追加C字符串，通过调用sdscatlen实现，导致剩余空间不够用时，会使用sdsMakeRoomFor增加空间，当追加字符串后所需的总的空间大小小于1MB时，会申请2倍的总空间大小的字节数；否则额外申请1MB空间。 sdscatsds 追加SDS字符串，通过调用sdscatlen实现，同上。 sdsclear 用于清空字符串，但不会释放申请的内存空间，这种惰性空间释放可以减少了内存重分配操作的次数。 sdscpy 将指定C字符串复制到SDS中，覆盖原有字符串 sdscatprintf 追加fmt字符串 sdstrim 接受一个SDS和一个C字符串，在SDS字符串左右两端分别去除在C字符串中出现过的字符 sdscmp 比较两个SDS字符串是否相同 sdsrange 保留SDS指定区间内的数据 sdsmapchars 根据所给符from和to的映射关系，替换SDS字符串中的对应字符 sdsjoin 用指定分隔符插入C字符串的字符之间，构成一个SDS sdsjoinsds 用指定分隔符插入SDS字符串的字符之间，构成一个新的SDS 懵逼点C99中的灵活数组类型不占用空间首先是这个宏，这个宏的作用是获取指定类型T的SDS头的指针 1#define SDS_HDR(T,s) ((struct sdshdr##T *)((s)-(sizeof(struct sdshdr##T)))) 使用该宏时，T传入SDS的类型，s传入sds字符串（成员buf[]的地址）。拿上面的sdshdr8为例，((s)-(sizeof(struct sdshdr8)))为什么能表示sds头的地址？ 首先，上面讲到，buf[]是个灵活数组类型，它在这里只是起到一个标记的作用，表示在flags字段后面就是一个字符数组，或者说，它指明了紧跟在flags字段后面的这个字符数组在结构体中的偏移位置。而程序在为header分配的内存的时候，它并不占用内存空间。所以sizeof(struct sdshdr8)为3。 attribute((format(printf, 2, 3)))在声明sdscatprintf函数时，给这个函数加上了__attribute__ format属性。 123456#ifdef __GNUC__sds sdscatprintf(sds s, const char *fmt, ...) __attribute__((format(printf, 2, 3)));#elsesds sdscatprintf(sds s, const char *fmt, ...);#endif __attribute__ format属性可以给被声明的函数加上类似printf或者scanf的特征，它可以使编译器检查函数声明和函数实际调用参数之间的格式化字符串是否匹配。format属性告诉编译器，按照printf, scanf等标准C函数参数格式规则对该函数的参数进行检查。 format的语法格式为： 1format (archetype, string-index, first-to-check) archetype 指定是哪种风格； string-index 指定传入函数的第几个参数是格式化字符串； first-to-check 指定从函数的第几个参数开始按上述规则进行检查。 敲重点！！！：可以用在自己封装调试信息的接口上。","link":"/2019/05/redis_ds_sds.html"},{"title":"Redis5.0源码 - 数据结构 - 字典","text":"字典，又称符号表、关联数组或映射，是一种用于保存键值对（key-value pair）的抽象数据结构。Redis使用的C语言并没有内置字典这种数据结构，所以Redis构建了自己的字典实现。 设计 相关文件：dict.h、dict.c Redis的字典使用哈希表作为底层实现。一个哈希表里可以有多个哈希表节点。每个哈希表节点保存着一个键值对。 哈希表的实现12345678910111213141516171819/* 哈希表节点，每个dictEntry结构都保存着一个键值对 */typedef struct dictEntry { void *key; // 键 union { // 值 void *val; uint64_t u64; int64_t s64; double d; } v; struct dictEntry *next; // 指向下一个哈希表节点，用于解决键冲突} dictEntry;/* 哈希表 */typedef struct dictht { dictEntry **table; // 哈希表节点数组 unsigned long size; // 哈希表大小 unsigned long sizemask; // 哈希表大小掩码，用于计算索引值，总是等于size-1 unsigned long used; // 该hash表已有节点的数量} dictht; 下图展示了一个大小为4的哈希表，其中k1和k0产生了键冲突，通过next形成了链表。 字典的实现1234567891011121314151617181920212223typedef struct dictType { /* 计算hash值的函数 */ uint64_t (*hashFunction)(const void *key); /* 复制键的函数 */ void *(*keyDup)(void *privdata, const void *key); /* 复制值的函数 */ void *(*valDup)(void *privdata, const void *obj); /* 对比键的函数 */ int (*keyCompare)(void *privdata, const void *key1, const void *key2); /* 销毁键的函数 */ void (*keyDestructor)(void *privdata, void *key); /* 销毁值的函数 */ void (*valDestructor)(void *privdata, void *obj);} dictType;/* 字典 */typedef struct dict { dictType *type; // 特定于类型的处理函数 void *privdata; // 类型处理函数的私有数据 dictht ht[2]; // 哈希表 long rehashidx; // rehash索引，当没进行rehash时，值为-1 unsigned long iterators; // 当前正在运行的迭代器数量} dict; 在这里可以看到，字典结构中用了两个哈希表，一般情况下只使用哈希表ht[0]，ht[1]只会在对哈希表h[0]进行rehash时被使用。 哈希算法12// 计算hash值#define dictHashKey(d, key) (d)-&gt;type-&gt;hashFunction(key) 在Redis5.0字典的哈希表底层实现时，计算hash值默认采用了SipHash 1-2算法替换了之前的Murmurhash2算法，并在siphash.c中实现。 rehash（重哈希）rehash指的就是因为哈希表size的变化，导致需要重新计算键的哈希值和索引值。 12// 是否正在rehash#define dictIsRehashing(d) ((d)-&gt;rehashidx != -1) 随着不断的操作，哈希表保存的键值对会逐渐增加或减少。为了使哈希表的装载因子（load factor）维持在一个合理范围，Redis使用rehash对哈希表进行伸缩。这里的rehashidx用于记录rehash的进度（例如当前rehash到ht[0].table[idx]处，则rehashidx等于idx的值。每一个ht[0].table[idx]在代码注释中被称为bucket（桶），即每个桶对应一个键，即每个桶都对应一个键值对的链表）。 扩容和缩容 扩容（_dictExpandIfNeeded）： 服务器没有执行bgsave或bgrewriteaof操作(dict_can_resize=1)，当hash表中元素的个数大于等于ht[0].size时，就会开始扩容，扩容的新数组的大小为第一个不小于ht[0].size * 2的2^n的数。 如果Redis正在做bgsave，为了减少内存页的过多分离 (Copy On Write)，Redis尽量不去扩容(dict_can_resize=0)。但是当元素的个数已经达到了ht[0].size的5倍 (dict_force_resize_ratio)，说明hash表已经过于拥挤了，这个时候就会强制扩容。 缩容（dictResize）：ht[1]的大小为第一个大于等于ht[0].used的2^n的数。 将ht[0]上的所有键值对rehash到ht[1]上（旧表ht[0]上删一个，新表ht[1]上增一个）。并且rehash不是一次完成（每次重哈希n个桶）。 迁移全部完成后，释放哈希表ht[0]，并将ht[1]设置成ht[0]，然后为ht[1]设置空表。 注：另外，字典rehash过程还会穿插到键值对的增加或删除操作中，即此时字典正在rehash，每次增加或删除操作过程中都会rehash一个bucket。 增加和删除键值对操作 增加： 首先需要判断该键值对是否存在：如果没在rehash，只查找表0；正在rehash，顺序查找表0和表1； 若不存在，则进行插入操作：如果没在rehash，插入表0；正在rehash，插入表1； 常用API 函数 作用 dictCreate 创建一个新的字典 dictRelease 清空和释放字典 dictEmpty 清空字典 dictAdd 在字典中加入一个键值对 dictDelete 在字典中删除指定的键值对 dictReplace 增加或覆盖键值对 dictRehash 单次rehash dictRehashMilliseconds rehash直到完成（每ms秒执行一次dictRehash） dictGetIterator 获取字典的迭代器对象 dictNext 根据提供的迭代器获取下一个键值对 dictReleaseIterator 释放迭代器 懵逼点将二进制逆序的奇技淫巧1234567891011/* Function to reverse bits. Algorithm from: * http://graphics.stanford.edu/~seander/bithacks.html#ReverseParallel */static unsigned long rev(unsigned long v) { unsigned long s = 8 * sizeof(v); // bit size; must be power of 2 unsigned long mask = ~0; while ((s &gt;&gt;= 1) &gt; 0) { mask ^= (mask &lt;&lt; s); v = ((v &gt;&gt; s) &amp; mask) | ((v &lt;&lt; s) &amp; ~mask); } return v;} PS：这个注释中的链接指向的页面里都是一些处理二进制的奇技淫巧，代码精简高效，但晦涩难懂。","link":"/2019/05/redis_ds_dict.html"},{"title":"linux0.12内核剖析 - 引导启动（一）","text":"从PC上电到进入系统初始化main函数的过程中，内核做了哪些事情？ 相关文件：boot/* 其中，bootsect.S和setup.S是实模式下运行的16位代码程序，采用近似于Intel的汇编语言语法，并且需要使用8086汇编编译器as86和链接器ld86。 head.s则使用一种AT&amp;T的汇编语法格式，并且运行在保护模式下，需要用GNU的as（gas）汇编器进行编译。 内核映像在磁盘中的格式 CPU执行权的移交CPU执行权的移交如下图所示： 当PC的电源打开后，80x86结构的CPU将自动进入实模式，并从地址0xFFFF0开始自动执行程序代码，这个地址通常是ROM BIOS中的地址。PC机的BIOS将执行系统的某些硬件检测和诊断功能，并在物理地址0处开始设置和初始化中断向量。此后，它将可启动设备的第一个扇区（磁盘引导扇区，512字节，也就是bootsect）读入内存绝对地址0x7C00处，并跳转到这个地方开始引导启动机器运行了。 内核在内存中的移动情况 BIOS将引导设备的第一个扇区（bootsect）读入到内存绝对地址0x7C00处； bootsect执行时将自己移动到内存绝对地址0x90000处； bootsect之后会将紧接着的4个扇区代码（setup）读入到内存0x90200处；再将之后的system模块读入到内存0x10000处（当时system不会超过0x80000字节，不会覆盖0x90000处开始的bootsect和setup）； bootsect最后跳转到setup中执行； setup又会把system移动到物理内存起始处0x00000； bootsect、setup、head各自干了啥bootsectbootsect把整个内核映像加载到了内存是它最大的贡献了（PS：只有它保存在0x901FC处的ROOT_DEV和0x901FA处的SWAP_DEV还被记得）。 将自己从0x7c00移动到0x90000处； 为了更快地加载内核，修改了软驱参数表； 加载setup模块到0x90000处； 加载system模块到0x10000处 干完活，跳转去setup。 setupsetup主要做了三件事：获取系统的一些参数，移动system模块，开启保护模式。 获取系统初始化所需要的参数； 把整个system模块移动到0x00000位置； 因为要开启保护模式，所以设置了一个临时的gdt表和ldt表； 将控制寄存器CR0位0置1，从而开启保护模式； 跳转到head中执行。 setup结束后，内存中的程序示意图如下所示 headhead很大一部分代码都是一次性的；用完就被页目录表和页表覆盖掉了。head主要为之后操作系统的运行留下了几件重要的东西：1个页目录表和4个内核专属的页表，中断描述符表IDT和全局段描述符表GDT，以及一个哑中断ignore_int。 将系统堆栈放置在stack_start指向的数据区（之后，该栈就被用作任务0和任务1共同使用的用户栈）； 重新加载了新的中断描述符表IDT和全局段描述符表GDT； 检查数学协处理器芯片是否存在； 初始化页目录表和4个内核专属的页表； 页目录表（4KB）从物理地址0处开始，紧接着4个内核专属的页表（4*4KB）； 通过ret跳转到init/main.c中的main运行。","link":"/2019/04/linux012_boot_01.html"},{"title":"bochs与gdb联调时忽略page fault信号","text":"bochs与gdb联调，在调试内核时经常会被page fault（signal 0）信号打断，如何忽略page fault信号呢？ 根据以下内容，修改bochs源码中的gdbstub.cc文件 1234567891011121314151617181920212223242526Created a patch &quot;gdbstub.cc.patch&quot; against bochs (version CVS 20080110)Bochs always tries to find out the reason of an exception, so that it can generate the right signal for gdb.If it fails to find a reason, bochs assigns a value GDBSTUB_STOP_NO_REASON (see bochs.h), which causesdebug_loop() (see gdbstub.cc) to generate a signal of number 0.Signal 0 is problematic to gdb, as gdb doesn't allow us to ignore it.Somehow when we simulate linux, we get tons of signal 0's that seem to be caused by page faults.This patch makes bochs send SIGSEGV instead of signal 0, so that we can ignore it in gdb.gdbstub.ccdebug_loop()*** gdbstub.cc.orig Thu Oct 18 18:44:38 2007--- gdbstub.cc Sat Jan 12 17:25:22 2008*************** static void debug_loop(void)*** 489,494 ****--- 489,498 ---- { write_signal(&amp;buf[1], SIGTRAP); }+ else if (last_stop_reason == GDBSTUB_STOP_NO_REASON)+ {+ write_signal(&amp;buf[1], SIGSEGV);+ } else { write_signal(&amp;buf[1], 0); 重新编译生成支持gdb调试的bochs二进制文件 12./configure --enable-gdb-stub --enable-disasmmake 附录 下载bochs源码 1wget https://downloads.sourceforge.net/project/bochs/bochs/2.6.9/bochs-2.6.9.tar.gz -q --show-progress 安装编译bochs的必要依赖 123sudo apt-get install -y build-essential libgtk2.0-dev libx11-dev xserver-xorg-dev xorg-dev g++ pkg-config libxcursor-dev libxrandr-dev libxinerama-dev libxi-dev# 选装sudo apt-get install -y bochs bochs-x bochs-sdl","link":"/2019/03/bochs_gdb_page_fault.html"},{"title":"Redis5.0源码 - 数据结构 - 链表","text":"Redis使用的C语言并没有内置链表这种数据结构，所以Redis构建了自己的链表实现。 设计 相关文件：adlist.h、adlist.c 跟Redis链表实现相关的数据结构如下： 1234567891011121314151617181920212223/* 链表节点结构 */typedef struct listNode { struct listNode *prev; // 前置节点 struct listNode *next; // 后置节点 void *value; // 节点的值} listNode;/* 链表遍历所使用的Iterator结构 */typedef struct listIter { listNode *next; int direction; // 遍历方向：0 - 从头开始，1 - 从尾开始} listIter;/* 链表结构 */typedef struct list { listNode *head; // 表头节点 listNode *tail; // 表尾节点 void *(*dup)(void *ptr); // 节点值复制函数 void (*free)(void *ptr); // 节点值释放函数 int (*match)(void *ptr, void *key); // 节点值对比函数 unsigned long len; // 链表长度} list; Redis的链表结构如下图所示 Redis链表的特点： 双向无环链表：首先，很显然Redis的链表是一个双向无环链表，获取当前节点的前驱节点和后驱节点的时间复杂度为O(1)； 有表头表尾指针：获取表头节点和表尾节点的时间复杂度为O(1)； 链表有len属性：获取链表长度的时间复杂度为O(1)； 多态：用void*指针来保存节点内容，并提供节点处理函数dup，free，match。可以用来存储不同类型。 常用API 函数 作用 listLength 返回链表长度 listFirst 返回表头 listLast 返回表尾 listPrevNode 返回当前节点的前置节点 listNextNode 返回当前节点的后置节点 listNodeValue 返回当前节点的值 listSetDupMethod 设置dup函数 listSetFreeMethod 设置free函数 listSetMatchMethod 设置match函数 listGetDupMethod(l) 获取dup函数 listGetFree(l) 获取free函数 listGetMatchMethod(l) 获取match函数 listCreate 创建一个不包含任何节点的新链表 listRelease 释放整个链表结构 listEmpty 删除链表的所有节点，使链表成为空链表，链表依旧存在 listAddNodeHead 在链表头部插入节点 listAddNodeTail 在链表尾部插入节点 listInsertNode 在指定节点前或后插入新节点，前后取决于参数after listDelNode 删除指定节点 listGetIterator 获取链表的迭代器，根据参数direction确定从头还是从尾开始 listNext 根据迭代器返回下一个节点 listReleaseIterator 释放迭代对象占用的内存 listDup 复制整个链表 listSearchKey 根据给定key查找节点 listIndex 根据index索引返回链表节点（head为索引0） listRewind 创建一个迭代器（迭代器由函数外部传入），从头开始 listRewindTail 创建一个迭代器（迭代器由函数外部传入），从尾开始 listRotate 将链表的表尾节点弹出，插入到链表的表头，成为新的表头 listJoin 将一个链表o追加到另一个链表l后，并清空o链表","link":"/2019/05/redis_ds_list.html"},{"title":"linux0.12内核剖析 - 镜像构建","text":"linux0.12内核源码在make之后，会生成三个主要的文件，分别为bootsect、setup、system。它们是如何组装到一起形成Image镜像的呢？ 相关文件：tools/build.c 该build.c文件将被独立编译成一个可执行文件build，只参与将bootsect、setup、system三个文件组合成一个映像文件Imgae，不会被包含到Imgae中，因此可以拿出来单独分析。 该执行文件在主目录下的Makefile中被使用，通过以下以下命令生成映像文件Image。 123Image: boot/bootsect boot/setup tools/system tools/build tools/build boot/bootsect boot/setup tools/system $(ROOT_DEV) $(SWAP_DEV) &gt; Image sync Image文件的结构linux0.12内核映像结构（即生成的Image文件，Image = bootsect(1) + setup(4) + system(...)）如下所示： 组成Image的三个文件的说明(了解即可)： bootsect = 32B的MINIX执行文件头结构 + 512B的代码和数据 setup = 32B的MINIX执行文件头结构 + 剩余部分的代码和数据 system = 1KB的a.out头结构 + 剩余部分的代码和数据 注意：所有头结构都是不需要的，需要去除掉。 build 干了什么build程序具体做了以下一些事（这里的扇区以1为第一个扇区）： 校验bootsect头部并去除，将剩余的代码和数据写入Image中的第1个扇区，并读取根设备号和交换设备号写入Image中的第1个扇区的506、507、508、509字节处； 校验setup头部并去除，将剩余的代码和数据写入Image中的第2~5个扇区，共四个扇区； 校验system头部并去除，将剩余的代码和数据写入Image中的setup之后的扇区（…）。","link":"/2019/04/linux012_buildtool_01.html"},{"title":"linux0.12内核剖析 - 引导启动（二）","text":"在用户能登录shell前，操作系统的初始化函数main做了什么？ 相关文件：init/main.c 首先在main函数中，内核进行了各方面的硬件初始化工作，包括陷阱门、块设备、字符设备和tty，还包括人工设置第一个任务（task 0）。待所有初始化工作完成后，程序就设置中断允许标志以开启中断，并切换到任务0中运行。到此时，可以说内核已基本完成所有设置工作。接下来内核会通过任务0创建几个最初的任务，运行shell程序并显示命令行提示符，从而Linux系统进入正常运行阶段。 init进程主要完成4件事： 安装根文件系统 代码首先调用系统调用setup()，用来收集硬盘设备分区表信息并安装根文件系统。 显示系统信息 打开一个终端设备tty0并复制其文件描述符以产生标准输入stdin、标准输出stdout和错误输出stderr设备，随后利用这些描述符在终端上显示一些系统信息。 执行资源配置文件rc 接着init()又新建了一个进程（进程2），内核以非交互形式执行/bin/sh程序，执行配置文件etc/rc中设置的命令。 执行登录shell程序 在一个无限循环中，为用户建立一个新的会话，并运行用户登录shell程序/bin/sh。 细节move_to_user_mode的分析 相关文件：include/asm/system.h 函数move_to_user_mode()是用于内核在初始化结束时人工切换（移动）到初始进程（任务0）去执行，即从特权级0代码转移到特权级3的代码中去运行。 通过调用门、中断门或陷阱门，CPU允许低级别（特权级3）的代码来调用或转移到高级别（特权级0）的代码中运行，但反之则不允许。因此，所使用的方法是模拟中断调用返回过程，即利用IRET指令来实现特权级的变更和堆栈的切换，从而把CPU执行控制流移动到初始任务0的环境中运行。 12345678910111213141516/* 利用iret指令实现从内核模式移到用户模式去执行初始任务0 */#define move_to_user_mode() \\__asm__ ( \\ \"movl %%esp,%%eax\\n\\t\" \\ \"pushl $0x17\\n\\t\" /* 将堆栈段选择符SS入栈 */ \\ \"pushl %%eax\\n\\t\" /* 将堆栈指针esp入栈 */ \\ \"pushfl\\n\\t\" /* 将标志寄存器eflags入栈 */ \\ \"pushl $0x0f\\n\\t\" /* 将Task0代码段选择符cs入栈 */ \\ \"pushl $1f\\n\\t\" /* 将下标1地址入栈 */ \\ \"iret\\n\" /* 执行中断返回指令，跳转到下标1处 */ \\\"1:\\tmovl $0x17,%%eax\\n\\t\" /* 初始化段寄存器指向本局部表的数据段 */ \\ \"mov %%ax,%%ds\\n\\t\" \\ \"mov %%ax,%%es\\n\\t\" \\ \"mov %%ax,%%fs\\n\\t\" \\ \"mov %%ax,%%gs\" \\ :::\"ax\")","link":"/2019/04/linux012_boot_02.html"},{"title":"linux0.12内核剖析 - 系统调用","text":"系统调用（通常称为syscalls）是Linux内核与上层应用程序进行交互通信的唯一接口。用户程序通过直接或间接（通过库函数）使用系统调用，即可使用内核资源，包括系统硬件资源。 POSIX标准和linux系统调用POSIX（Portable Operating System Interface，可移植操作系统接口）是由IEEE和ISO/IEC开发的一簇标准。该标准是基于现有的UNIX实践和经验，描述了操作系统的调用服务接口，用于保证编制的应用程序可以在源代码一级上在多种操作系统上移植运行。 0.12内核共有87个系统调用功能。这些功能号定义在文件include/unistd.h中，格式为__NR_xxx。这些功能号实际上对应于include/linux/sys.h中定义的系统调用处理程序指针数组表sys_call_table[]的索引值。 通过printf由浅入深看系统调用的实现 相关文件：kernel/sys_call.s 、include/unistd.h、include/linux/sys.h、lib/write.c 当应用程序经过库函数向内核发出一个中断调用int 0x80时，就开始执行一个系统调用，其中寄存器eax中存放着系统调用号来区分是哪个系统调用请求。携带的参数则会依次存放在寄存器ebx、ecx和edx中。 例如，用户态下write函数的操作，实际会由操作系统利用int 0x80中断进入内核态，执行对应的sys_write来完成。 例如，在include/unistd.h中，write系统调用功能号为 1#define __NR_write 4 对应include/linux/sys.h中sys_call_table[]的第4项 12fn_ptr sys_call_table[] = { sys_setup, sys_exit, sys_fork, sys_read,sys_write, ...}; 在init/main.c文件中，可以看到printf实际上使用了write这个系统调用。 12345678910int printf(const char *fmt, ...){ va_list args; int i; va_start(args, fmt); write(1, printbuf, i = vsprintf(printbuf, fmt, args)); va_end(args); return i;} 在lib/write.c中，我们可以看到write系统调用的实现， 1_syscall3(int, write, int, fd, const char *, buf, off_t, count) 可以在include/unistd.h中，看出_syscall3是一个宏定义，我们根据这个宏定义将write展开，从而可以得到这样一个含有内嵌汇编的函数， 1234567891011int write(int fd, const char * buf, off_t count){ long __res; __asm__ volatile (\"int $0x80\" : \"=a\" (__res) : \"0\" (__NR_write), \"b\" ((long)(fd)), \"c\" ((long)(buf)), \"d\" ((long)(count))); if (__res &gt;= 0) return (int) __res; errno = -__res; return -1;} 可以看出write函数利用了int $0x80中断，并将__NR_write功能号和参数传了进去。中断0x80即为系统调用，在sched_init中设置了对应的中断处理函数地址， 12345void sched_init(void){ ... set_system_gate(0x80,&amp;system_call);} 所以，接下来会去执行system_call程序（在kernel/sys_call.s中），其中关键的一句代码如下（eax即为__NR_write，其中的4指的是每个函数指针大小为4），这句代码意思就是去执行sys_call_table+%eax*4处的函数，即sys_write， 1234system_call: ... call *sys_call_table(,%eax,4) ... 在内核态下，执行系统调用处理程序sys_write。","link":"/2019/04/linux012_syscall_01.html"},{"title":"linux0.12内核剖析 - 内存管理（一）","text":"linux-0.12内存管理的基本概念。 内存地址映射时的三种地址Linux0.12内核中， 在进行内存的地址映射操作时有3种地址： 虚拟地址（Virtual Address）是指由程序产生的由段选择符和段内偏移地址两个部分组成的地址，这里的段内偏移也被称为逻辑地址。用于程序内部寻址。 线性地址（Linear Address）是指段选择符所指向的段描述符中的段基址值加上段内偏移计算得出的地址。 物理地址（Physical Address）是最终寻址物理内存的地址，是地址变换的最终结果地址。 启用了分页机制，那么线性地址会使用页目录和页表中的项变换成物理地址。 没有启用分页机制，那么线性地址就是物理地址。 虚拟地址到物理地址的变换过程如下图所示： 分段机制（虚拟地址到线性地址的转换）CPU在实模式和保护模式下寻址方式的不同 在实模式下，寻址一个内存地址主要是使用段寄存器和段内偏移值就足够了，段寄存器中直接存放段基值，且段的长度被固定为64KB。 而在保护模式下，则额外需要一张段描述符表（Segment Descriptor Table）。段寄存器中存放的是段选择符（是一个段描述符表中某一描述符项在表中的索引值）。该索引值指定的段描述符项中含有需要寻址的内存段的基地址、段的长度值和段的访问特权级别等信息。 保护模式下用到的三种描述符表 全局描述符表（GDT Global Descriptor Table）是主要的基本描述符表，该表可被所有程序用于引用访问一个内存段。 中断描述符表（IDT Interrupt Descriptor Table）保存有定义中断或异常处理过程的段描述符。 IDT表直接替代了8086系统中的中断向量表。 局部描述符表（LDT Local Descriptor Table）应用于多任务系统中，通常每个任务使用一个LDT表。作为对GDT表的扩充，每个LDT表为对应任务提供了更多的可用描述符项，因而也为每个任务提供了可寻址内存空间的范围。这些表可以保存在线性地址空间的任何地方。 在Linux0.12系统中，一个任务的代码段和数据段的段限长相同，并被映射到线性地址完全相同而重叠的区域上。以任务2为例，虚拟地址、线性地址和物理地址之间的关系如下图 段选择符和段描述符段选择符（或称段选择子）是段的一个16位标识符，保护模式下段寄存器中的值。 段选择符的3个字段内容： 请求特权级RPL（Requested Privilege Level）提供段保护信息 表指示标志TI （Table Index） TI = 0 描述符在GDT中 TI = 1 描述符在LDT中 索引值（ Index ） 段描述符是GDT和LDT表中的一个数据结构项，用于向处理器提供有关一个段的位置和大小信息以及访问控制的状态信息。每个段描述符长度是8字节，含有三个主要字段：段基地址、段限长和段属性。 分页机制（线性地址到物理地址的映射）分段机制把虚拟地址转换成线性地址，而分页则把线性地址转换成物理地址。 我们通过设置控制寄存器CR0的PG位可以启用分页机制。如果PG=1，则启用分页操作。当使用分页时，处理器会把线性地址空间划分成固定大小的页面（长度为4KB），这些页面可以映射物理内存中或磁盘存储空间中（这种方式被称为虚拟存储或者需求页（Demand-paged）虚拟存储）。 进程空间映射到线性地址空间 在linux0.12中，每个进程能够使用64M内存，并且每个进程的逻辑地址空间在线性地址空间中都是从nr*64MB 的地址位置开始（nr 是任务号）。其中，最后部的环境参数数据块最长为128K，其左面是起始堆栈指针。另外，图中bss是进程未初始化的数据段，在进程创建时bss段的第一页会被初始化为全零。 请还需注意，进程逻辑地址空间中代码段（ Code Section ）和数据段（ Data Section ）的概念与CPU分段机制中的代码段和数据段不是同一个概念。 CPU分段机制中段的概念确定了在线性地址空间中一个段的用途以及被执行或访问的约束和限制，每个段可以设置在4GB线性地址空间中的任何地方，它们可以相互独立也可以完全重叠或部分重叠。 进程在其逻辑地址空间中的代码段和数据段则是指由编译器在编译程序和操作系统在加载程序时规定的在进程逻辑空间中顺序排列的代码区域、初始化和未初始化的数据区域以及堆栈区域。 线性地址映射到物理地址linux0.12采用了两级页表结构。第一级表称为页目录表（page directory），第二级表称为页表（page table）。 由CR3寄存器指定页目录表的基地址，线性地址的高10位用于索引页目录表，以获取页表所在位置；线性地址中间 10 位用于索引二级页表，以获得物理地址的高 20 位；线性地址的低12位直接作为物理地址低12位（页内偏移）；从而组成一个完整的32位物理地址。 页目录表项和页表项结构页目录项和页表项（4字节）的结构为 P - 位0是存在（Present）标志，用于指明表项对地址转换是否有效。P=1 表示有效；P=0 表示无效。 在页转换过程中，如果说涉及的页目录或页表的表项无效，则会导致一个异常。如果 P=0，那么除表示表项无效外，linux-0.12可以使用其他位来保存在交换空间的页面号。 所以根据表项内容可以判断： 表项为0 - 该表项无效； P = 1 - 该项指向的页面在物理内存中； P = 0，但表项不为0 - 该项指向的页面在交换空间中。 R/W - 位1是读/写（Read/Write）标志。如果等于 1，表示页面可以被读、写或执行。如果为 0，表 示页面只读或可执行。当处理器运行在超级用户特权级（级别 0、1 或 2）时，则 R/W 位不起作用。 U/S - 位2是用户/超级用户（User/Supervisor）标志。如果为 1，那么运行在任何特权级上的程序都可以访问该页面。如果为 0，那么页面只能被运行在超级用户特权级（0、1 或 2）上的程序访问。 A - 位5是已访问（Accessed）标志。当处理器访问页表项映射的页面时，页表表项的这个标志就会 被置为 1。当处理器访问页目录表项映射的任何页面时，页目录表项的这个标志就会被置为 1。处理器只负责设置该标志，操作系统可通过定期地复位该标志来统计页面的使用情况。 D - 位6是页面已被修改（Dirty）标志。当处理器对一个页面执行写操作时，就会设置对应页表表项 的 D 标志。处理器并不会修改页目录项中的D标志。 AVL - 该字段保留专供程序使用。处理器不会修改这几位，以后的升级处理器也不会。","link":"/2019/04/linux012_mem_manage_01.html"},{"title":"linux0.12内核剖析 - 内存管理（三）","text":"linux0.12内存管理中，分页机制的实现。 分页机制下对物理内存和交换空间的管理一、物理内存的管理 相关文件：mm/memory.c 对于linux0.12内核，它默认最多支持16M物理内存。在一个具有16MB内存的80x86计算机系统中，物理内存从低到高分别为 对于内核代码和数据所占物理内存区域以外的内存（1MB以上内存区域），内核使用了一个字节数组mem_map[]来管理物理内存页面（一页为4KB）的状态。每个字节描述一个物理内存页的占用状态。其中的值表示被占用的次数，0表示对应的物理内存空闲着。当申请一页物理内存时，就将对应字节的值增1。当值为100时，表示已被完全占用，不能再被分配。 初始化：mem_init会初始化mem_map[]，系统首先把mem_map[]所有项都置为100（占用），然后把主内存区域对应的mem_map[]项中的值清0。 申请物理内存：get_free_page会在mem_map[]从尾到头的查找值为0的项返回，如果没找到空闲页面，则会执行swap_out换出操作。 释放物理内存：free_page用于释放物理内存的1页内存；若页面在交换设备中，则用swap_free释放。 二、交换空间的管理 相关文件：mm/swap.c 从0.12版本开始，内核中增加了虚拟内存交换功能。在物理内存容量有限并且使用紧张时，本程序会将暂时不用的内存页面内容临时输出保存到交换设备上，以腾出内存空间给急需的程序使用。若此后要再次使用到已保存到磁盘上的内存页面内容，这本程序再负责将它们换回到内存中去。 内存交换管理使用了与主内存区管理相同的位图映射技术，使用比特位图来确定被交换的内存页面具体的保存位置和映射位置。初始化完成后，交换页面位图会占用一个物理页面，由于一个页面共有SWAP _BITS（40968）个比特位，因此交换分区可管理页面数最多不超过32768 个页面，即*最多换出不超过128MB物理内存（实际，以交换分区大小swap_size为准）**。 初始化：init_swapping会初始化一个交换页面位图swap_bitmap（该位图存在一页物理内存页面中），在交换页面位图中，swap_bitmap[1 ~ swap_size-1]可用。比特位值为1表示交换页面空闲可用，0表示不可用。 换出到交换设备：swap_out用于将一页物理内存页面换出到交换空间。该函数会调用try_to_swap_out函数对从FIRST_VM_PAGE起每一页物理内存尝试换出，直到换出一页为止，换出规则为： 当前页面未被修改，则直接释放该页面即可。毕竟重新从文件读入和从交换空间换入效率相差不大。 当前页面被修改过，则尝试换出（若该页面又是被共享的，不宜换出）。 换入到物理内存：swap_in用于把指定页面交换进物理内存中。 释放：swap_free用于释放交换设备中指定的交换页面。","link":"/2019/04/linux012_mem_manage_03.html"},{"title":"linux0.12内核剖析 - 内存管理（二）","text":"内存保护。 保护处理器寄存器的2个比特位定义了当前执行程序的特权级，称为当前特权级（CPL Current Privilege Level ）。 对于分段机制，处理器使用段寄存器中选择符（RPL和CPL）和段描述符中各个字段执行保护验证。 对于分页机制，则主要利用页目录和页表项中的R/W和U/S标志来实现保护操作。 分段级保护机制下的特权级检查对于分段级保护机制，处理器使用段寄存器中选择符（RPL和CPL）和段描述符中各个字段执行保护验证，即特权级检查。这种保护机制是可靠的多任务运行环境所必须的。它可用于保护各个任务免受相互之间的干扰。例如普通的用户进程试图去获取root密码。 Intel80X86 CPU共分4个保护级，0级具有最高优先级，而3级优先级最低。数值越大，特权越小。Linux0.12使用了CPU的0和3两个保护级。同时，硬件提供了用户程序进入内核的唯一方式，即中断指令int，int指令会将CS中的CPL改为0，从而进入内核。 CPL：（Current Privilege Level，当前特权级）。CPL是当前正在执行程序或任务的特权级，它存放在CS和SS段寄存器的位0和位1中。通常，CPL等于当前代码段（CS）的特权级。 DPL：（Descriptor Privilege Level，描述符特权级）。DPL是一个段或门的特权级，它存放在段或门描述符的DPL字段中。在当前执行代码段试图访问一个段或门时，段或门的DPL会用来与CPL以及段或门选择符中的RPL（见下面说明）作比较。 RPL：（Request Privilege Level，请求特权级）。 RPL是一种赋予段选择符的超越特权级，它存放在选择符的位0和位1中。处理器会同时检查RPL和CPL，以确定是否允许访问一个段。即使程序或任务具有足够的特权级（CPL）来访问一个段，但是如果提供的RPL特权级不足的话访问也将被拒绝。 也就是说，只有当DPL&gt;=CPL、DPL&gt;=RPL时，当前特权级的任务才能访问对应的目标段内存。如下图所示","link":"/2019/04/linux012_mem_manage_02.html"},{"title":"linux0.12内核剖析 - 文件系统（四）","text":"通过open打开文件操作探究linux0.12的文件系统。 系统调用open是进程要存取一个文件中数据所必须采取的第一步（fs/open.c）。系统调用open的语法格式是： 1fd = open(pathname, flags, mode); 这里，pathname是文件名；flags指示打开的类型（读或写等）；mode给出文件的许可权（如果文件正在被建立）。open调用成功会返回一个称为文件描述符的整数fd。 这个fd到底代表什么呢？首先，我们需要知道每个任务（进程）结构中都会有一个用户文件描述符表（即filp[NR_OPEN]数组），fd即为该数组的索引。 filp[fd]为一个文件结构的指针，指向系统内核中的文件表file_table[NR_FILE]的某个文件结构；文件结构file中保存有本文件被句柄引用的次数、偏移指针等以及用于找到文件的i节点指针； 文件结构中的i节点指针指向内存中的索引节点表中对应的i节点，然后就可以找到文件了。 需要明确的一点是，每个进程都有自己的用户文件描述符表，而系统内核中只有一个文件表和一个内存i节点表。每次open调用都会在进程的用户文件描述符表和内核的文件表中各分配一个表项。但在内核的索引节点表中，每个文件只有唯一的一个表项。 代码解析1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/*** 打开(或创建)文件* @note 实际上open的操作是将进程中的文件描述符指向了系统中的文件表项，该文件表项又指向了打开的文件* 索引节点(inode)。* @param[in] filename 文件名* @param[in] flag 打开文件标志* @param[in] mode 文件属性* @retval 成功返回文件句柄，失败返回出错码*/int sys_open(const char * filename, int flag, int mode){ struct m_inode * inode; struct file * f; int i, fd; mode &amp;= 0777 &amp; ~current-&gt;umask; /* 1. 在用户文件描述符表找到最小的文件描述符fd */ for(fd = 0; fd &lt; NR_OPEN; fd ++) { if (!current-&gt;filp[fd]) { break; } } if (fd &gt;= NR_OPEN) { return -EINVAL; } current-&gt;close_on_exec &amp;= ~(1&lt;&lt;fd); /* 2. 在文件表中找到空闲的文件结构项 */ f = 0 + file_table; for (i = 0; i &lt; NR_FILE; i++, f++) { if (!f-&gt;f_count) { break; } } if (i &gt;= NR_FILE) { return -EINVAL; } (current-&gt;filp[fd] = f)-&gt;f_count++; /* 3. 在内存的索引节点表中找到文件对应的i节点 */ if ((i = open_namei(filename, flag, mode, &amp;inode)) &lt; 0) { current-&gt;filp[fd] = NULL; f-&gt;f_count = 0; return i; }/* ttys are somewhat special (ttyxx major==4, tty major==5) */ if (S_ISCHR(inode-&gt;i_mode)) { if (check_char_dev(inode, inode-&gt;i_zone[0], flag)) { iput(inode); current-&gt;filp[fd] = NULL; f-&gt;f_count = 0; return -EAGAIN; } }/* Likewise with block-devices: check for floppy_change */ if (S_ISBLK(inode-&gt;i_mode)) { check_disk_change(inode-&gt;i_zone[0]); } f-&gt;f_mode = inode-&gt;i_mode; f-&gt;f_flags = flag; f-&gt;f_count = 1; f-&gt;f_inode = inode; f-&gt;f_pos = 0; return (fd);}","link":"/2019/04/linux012_file_system_04.html"},{"title":"linux0.12内核剖析 - 文件系统（三）","text":"linux0.12文件系统中，高速缓冲区的实现。 在linux0.12中，内核不会直接去操作磁盘文件系统中的各种结构以及文件数据等，内核会先将它们从磁盘中拷贝到内存中的高速缓冲区，然后去操作他们。高速缓冲区是文件系统访问块设备中数据的必经要道。（fs/buffer.c） 高速缓冲区在物理内存中的分配高速缓冲区在物理内存中的分配，以机器的物理内存大小为16MB举例，会从内核代码结束的位置end开始到物理内存4M处结束（但中间640K～1M不会使用，它们被用于显存和BIOS ROM）。 高速缓冲区占用的物理内存（物理内存分配图的黄色部分）在初始化过程中（buffer_init()），内存低端会被初始化成缓冲头buffer_head，内存高端为缓冲数据块(大小为1024B)； 缓冲区的数据结构缓冲头的数据结构： 123456789101112131415struct buffer_head { char * b_data; /* 指向缓冲数据块的指针 */ unsigned long b_blocknr; /* 块号 */ unsigned short b_dev; /* 数据源的设备号 */ unsigned char b_uptodate; /* 更新标志：表示数据是否已更新 */ unsigned char b_dirt; /* 修改标志：0未修改，1已修改 */ unsigned char b_count; /* 使用用户数 */ unsigned char b_lock; /* 缓冲区是否被锁定 0 - ok, 1 -locked */ struct task_struct * b_wait; /* 指向等待该缓冲区解锁的任务 */ /* 这四个指针用于缓冲区的管理 */ struct buffer_head * b_prev; /* hash队列上的前一块 */ struct buffer_head * b_next; /* hash队列上的后一块 */ struct buffer_head * b_prev_free; /* 空闲表上的前一块 */ struct buffer_head * b_next_free; /* 空闲表上的后一块 */}; 其中buffer_head中的b_data会指向对应的缓冲块；同时在初始化过程中，会初始化缓冲头中的四个重要的指针b_prev、b_next、b_prev_free和b_next_free。 所有缓冲头会通过b_prev_free和b_next_free被链接成一个双向链表结构，称为空闲链表free_list。在系统的运行过程中，所有缓冲头始终都会在空闲链表上。 其中b_prev、b_next指针用于hash表中散列在同一项上多个缓冲块之间的双向链接，会暂时被初始化为NULL，即不处于任何一个hash表项中。 高速缓冲区的管理，实际上可以认为是在对缓冲头的管理。缓冲块即看作磁盘文件数据在内存中的拷贝。","link":"/2019/04/linux012_file_system_03.html"},{"title":"linux0.12内核剖析 - 文件系统（一）","text":"MINIX文件系统的介绍，以及文件系统中重要的数据结构 - i节点。 MINIX文件系统总览在实现linux0.12文件系统时，Linus主要参考了《MINIX操作系统设计和实现》，使用了1.0版的MINIX文件系统（其主要结构定义在include\\linux\\fs.h）。 MINIX文件系统与标准UNIX的文件系统基本相同，它由6个部分组成：引导块、超级块、i节点位图、逻辑块位图、i节点、数据块。首先，一个磁盘被划分成以1KB为的单位的磁盘块。 引导块，存放BIOS自动读入的执行代码和数据，用于加载内核（即linux0.12中的bootsect） 超级块，用于存放盘设备上文件系统结构的结构信息，它决定了其他结构占用磁盘的大小和文件系统的一些属性 i节点位图，1比特位代表1个i节点的使用情况 逻辑块位图，1比特位代表1个磁盘块的使用情况 之后若干磁盘块存放文件的i节点结构，每个i节点存放有1个文件或目录的索引信息（文件长度，数据块在磁盘上的位置等） 最后是文件数据区，用于存放文件数据 引导块引导块是开机时由BIOS自动读入的执行代码和数据的盘块。但一个系统中并非所有盘设备都用作引导设备，对于非引导盘，仍然需要空出引导块的位置，这一盘块中可以不含任何内容。 另外，有些硬盘会被划分出几个分区，并且在每个分区中都可存放一个不同的文件系统。例如，下图中的硬盘划分成了4个分区，分别存放着FAT32、NTFS、MINIX和EXT2文件系统。硬盘的第一个扇区是主引导扇区，其中存放着硬盘引导程序和分区表信息。分区表中的信息指明了硬盘上每个分区的类型、在硬盘中起始位置参数和结束位置参数以及占用的扇区总数。 超级块超级块用于存放盘设备上文件系统的结构信息，并说明各部分的大小。 123456789101112131415161718192021struct super_block { unsigned short s_ninodes; /* 节点数 */ unsigned short s_nzones; /* 逻辑块数 */ unsigned short s_imap_blocks; /* i节点位图所占用的数据块数 */ unsigned short s_zmap_blocks; /* 逻辑块位图所占用的数据块数 */ unsigned short s_firstdatazone; /* 第一个数据逻辑块号 */ unsigned short s_log_zone_size; /* Log2(数据块数/逻辑块) */ unsigned long s_max_size; /* 文件最大长度 */ unsigned short s_magic; /* 文件系统魔数 */ /* 以下是内存中特有的 */ struct buffer_head * s_imap[8]; /* i节点位图缓冲块指针数组(占用8块) */ struct buffer_head * s_zmap[8]; /* 逻辑块位图缓冲块指针数组(占用8块) */ unsigned short s_dev; /* 超级块所在设备号 */ struct m_inode * s_isup; /* 被安装的文件系统根目录的i节点(isup-superi) */ struct m_inode * s_imount; /* 被安装到的i节点 */ unsigned long s_time; /* 修改时间 */ struct task_struct * s_wait; /* 等待该超级块的进程 */ unsigned char s_lock; /* 被锁定标志 */ unsigned char s_rd_only; /* 只读标志 */ unsigned char s_dirt; /* 已修改(脏)标志 */}; 在Linux0.12系统中，被加载的文件系统超级块保存在super_block[]数组中（共有8项，因此最多同时加载8个文件系统）。在内核初始化过程中，进程1（init进程）会执行系统调用setup，从而调用mount_root()，会初始化超级块表，同时安装根文件系统。 read_super函数会为新加载的文件系统在表中设置一个超级块项，put_super函数中释放超级块表中指定的超级块项。 i节点位图i节点用于存放盘设备上每个文件和目录名的索引信息。i节点位图用于说明i节点是否被使用，同样是每个比特位代表一个i节点。当所有i节点都被使用时，查找空闲i节点的函数会返回0值，因此i节点位图的比特位0和对应的i节点0都闲置不用。 逻辑块位图逻辑块位图用于描述盘上每个数据盘块的使用情况。除第1个比特位（位0）以外，逻辑块位图中每个比特位依次代表盘上数据区中的一个逻辑块。因此，逻辑块位图的比特位1代表盘上数据区中第一个数据盘块，而非盘上的第一个磁盘块（引导块）。 从超级块结构体可以看出，逻辑块位图最多使用8块缓冲块（s_zmap[8]），一个缓冲块能代表8192个盘块（每个盘块为1KB），因此，MINIX文件系统1.0所能支持的最大块设备容量是64MB。 i节点i节点部分存放着文件系统中文件或目录名的索引节点，每个文件或目录名都有一个i节点。每个i节点结构中存放着对应文件或目录的相关信息，如文件宿主的id(uid)、文件所属组 id（gid）、文件长度、访问修改时间以及文件数据块在盘上的位置等。 数据区以块为单位，用于存储文件数据的地方。 文件的索引信息 - i节点每个文件或目录名都有一个i节点，用于存放着对应文件或目录的相关信息。 123456789101112131415161718192021222324struct m_inode { unsigned short i_mode; /* 文件类型和属性(rwx位) */ unsigned short i_uid; /* 用户id(文件拥有者标识符) */ unsigned long i_size; /* 文件大小(字节数) */ unsigned long i_mtime; /* 修改时间(自1970.1.1.:0算起，秒) */ unsigned char i_gid; /* 组id(文件拥有者所在的组) */ unsigned char i_nlinks; /* 链接数(多少个文件目录项指向该i节点) */ unsigned short i_zone[9]; /* 直接(0-6)，间接(7)或双重间接(8)逻辑块号 */ /* zone是区的意思，可译成区段，或逻辑块 */ /* 以下是内存中特有的 */ struct task_struct * i_wait; /* 等待该i节点的进程 */ struct task_struct * i_wait2; /* for pipes */ unsigned long i_atime; /* 最后访问时间 */ unsigned long i_ctime; /* i节点自身修改时间 */ unsigned short i_dev; /* i节点所在的设备号 */ unsigned short i_num; /* i节点号 */ unsigned short i_count; /* i节点被使用的次数，0表示该i节点空闲 */ unsigned char i_lock; /* 锁定标志 */ unsigned char i_dirt; /* 已修改(脏)标志 */ unsigned char i_pipe; /* 管道标志 */ unsigned char i_mount; /* 安装标志 */ unsigned char i_seek; /* 搜寻标志(lseek时) */ unsigned char i_update; /* 更新标志 */}; i_zone字段一个文件名通过对应的i节点与这些数据磁盘块相联系，这些盘块的号码就被存放在i节点的逻辑块数组i_zone[]中。 i_zone[0]到i_zone[6]用于存放文件开始的7个磁盘块号，称为直接块。若文件长度小于等于7K字节，则根据其i节点可以很快就找到它所使用的盘块。若文件大一些时，就需要用到一次间接块了（i_zone[7]），这个盘块中存放着附加的盘块号。对于MINIX文件系统一个盘块中可以存放（1024/2）=512个盘块号，因此可以寻址512个盘块。若文件还要大，则需要使用二次间接盘块（i_zone[8]）。二次间接块的一级盘块的作用类似与一次间接盘块，因此使用二次间接盘块可以寻址512*512个盘块。对于MINIX文件系统1.0版来说，一个文件的最大长度为(7+512+512*512)=262,663KB。 i_mode字段其中i_mode字段用来保存文件的类型和访问权限属性。其比特位15-12用于保存文件类型，位11-9保存执行文件时设置的信息，位8-0表示文件的访问权限。（include/sys/stat.h和include/fcntl.h） UNIX类操作系统中的文件通常可分为6类（include/sys/stat.h）： 123456789101112#define S_IFMT 00170000 /* 文件类型位屏蔽码(8进制表示) *//* 文件类型 */#define S_IFLNK 0120000 /* 符号链接 */#define S_IFREG 0100000 /* 常规文件 */#define S_IFBLK 0060000 /* 块特殊(设备)文件，如磁盘dev/fd0 */#define S_IFDIR 0040000 /* 目录 */#define S_IFCHR 0020000 /* 字符设备文件 */#define S_IFIFO 0010000 /* FIFO特殊文件 *//* 文件类型的判断 */#define S_ISLNK(m) (((m) &amp; S_IFMT) == S_IFLNK) /* 是否为符号链接文件 */... 目录项结构因为文件目录结构的存在，系统才能将文件名和i节点一一对应起来（根目录/的i节点号固定为1）。 12345678#define NAME_LEN 14 /* 文件名长度值 */#define ROOT_INO 1 /* 根i节点 *//* 文件目录项结构 */struct dir_entry { unsigned short inode; /* i节点号 */ char name[NAME_LEN]; /* 文件名，长度NAME_LEN=14 */}; 在打开一个文件时，文件系统会根据给定的文件名找到其i节点号，从而通过其对应i节点信息找到文件所在的磁盘块位置。 例如对于要查找文件名/usr/bin/vi的i节点号，文件系统首先会从根目录开始操作，即从i节点号1的数据块中查找到名称为usr的目录项，从而得到文件/usr的i节点号。根据该i节点号找到对应的文件内容（即目录），并在其中可以查找到文件名bin的目录项，这样就知道了/usr/bin的i节点号…最终,我们可获得文件路径名/usr/bin/vi的i节点号，从而可以从磁盘上得到该文件的内容。","link":"/2019/04/linux012_file_system_01.html"},{"title":"linux0.12内核剖析 - 文件系统（二）","text":"linux0.12文件系统的设计结构，简析fs目录下各文件的功能。 文件系统的系统调用 存取已存在文件：open、read、write、lseek、close 创建新文件：creat、mkmod 管理索引节点和文件系统：chdir、chroot、chmod、stat、fstat 管道相关：pipe、dup 挂载文件系统：mount、umount 修改文件层次：link、unlink 与文件系统相关的目录 buffer.c 高速缓冲区的相关操作 get_hash_table 在高速缓冲区中寻找指定的缓冲块 getblk 取高速缓冲中指定的缓冲块 brelse 释放指定缓冲块 bread、breada、bread_page 从设备上读取指定数据块（一块、多块或一页）到高速缓冲区 bitmap.c i节点位图和逻辑块位图的相关操作 free_block 释放设备dev上数据区中的block号逻辑块 new_block 向设备dev申请一个逻辑块 free_inode 释放指定的i节点 new_inode 在设备dev上创建一个新i节点 super.c 超级块的相关操作 get_super 取指定设备dev的超级块结构体指针 put_super 释放指定设备dev的超级块 系统调用: umount、mount truncate.c 文件截断 truncate 截断文件，即释放文件占用的空间 inode.c bmap 取文件数据块block在设备上对应的逻辑块号 iput 放回一个i节点 iget 取得一个i节点 namei.c _namei 根据指定路径名寻找对应的i节点 系统调用：mknod、mkdir、rmdir、link、unlink、symlink read_write.c 为不同文件类型的读写操作提供统一的接口 系统调用：read、write、lseek open.c 系统调用: ustat、utime、access、chdir、chroot、chmod、chown、open、creat、close fcntl.c 系统调用：dup、dup2、fcntl select.c 系统调用：select stat.c 系统调用：stat、lstat、fstat、readlink -ioctl.c - 系统调用：ioctl exec.c 系统调用：exec簇","link":"/2019/04/linux012_file_system_02.html"},{"title":"经典IPC问题 - 哲学家进餐问题","text":"在1965年，Dijkstra提出并解决了一个他称之为哲学家进餐的同步问题。从那时起，每个发明新的同步原语的人都希望通过解决哲学家进餐问题来展示其同步原语的精妙之处。 哲学家进餐问题对于多个竞争进程互斥地访问有限资源（如VO设备）这一类问题的建模十分有用。这个问题可以简单地描述如下：五个哲学家围坐在一张圆桌周围，每个哲学家的前面都有一碟通心面，由于面条很滑，所以要两把叉子才能夹住，相邻两个碟子之间有一把叉子。 哲学家的生活包括两种活动，即吃饭和思考。当一个哲学家觉得饿时，他就试图分两次去取他左边和右边的叉子，每次拿一把，但不分次序。如果成功地获得了两把叉子，他就开始吃饭，吃完以后放下叉子继续思考。 这里的问题就是：为每一个哲学家写一段程序来描述其行为，要求不能死锁。 方案一（死锁）：过程take_fork将一直等到所指定的叉子可用，然后将其取用。遗憾的是，这种解法是错误的。设想所有五个哲学家都同时拿起左面的叉子，则他们都拿不到右面的叉子，于是发生死锁。 123456789101112#define N 5 /* 哲学家数目 */void philosopher(int i) { /* i：哲学家号码，从0到4 */ while(TRUE) { think(); /* 哲学家正在思考 */ take_fork(i); /* 取左叉 */ take_fork((i+1)%N); /* 取右叉；%为取余 */ eat(); /* 吃面*/ put_fork(i); /* 放回左叉 */ put_fork((i+1)%N); /* 放回右叉 */ }} 方案二（饥饿）：规定在拿到左叉后，查看右面的叉子是否可用。如果不可用，则先放下左叉，等一段时间后再重复整个过程。可能在某一个瞬间，所有的哲学家都同时启动这个算法，拿起左叉，看到右叉不可用，又都放下左叉等一会儿，又同时拿起左叉，如此这样永远重复下去：所有的程序都在运行，但却无法取得进展这种情况就称为饥饿（starvation）。 方案三（不可靠）：如果哲学家在拿不到右叉时等待一段随机的时间，而不是等待相同的时间，则长时间处于上述死锁状态的机会就很小了。这种想法是对的，而且在大多数应用中，稍后试的方法也不成问题。例如，在使用以太网的局域网时，检测到数据包碰撞，每台电脑等待一段随机的时间后重试。 方案四（效率低）：使用一个二进制信号量对think函数之后的五条语句进行保护。在哲学家开始拿叉子之前，先对信号量mutex执行down操作。放回叉子后，再对mutex执行up操作。从理论上讲，这种解法是可行的。但从实际角度看，同一时刻只能有一个哲学家进餐。而五把叉子实际允许两个哲学家时进餐。 方案五：下面的解法不仅正确，而且能获得最大的并行度。其中使用一个数组state来跟踪一个哲学家是在吃饭、思考还是正在试图拿叉子：一个哲学家只有在两个邻居都不在进餐时才允许进入到进餐状态。第i位哲学家的邻居由宏LEFT和RIGHT定义。 哲学家进餐问题的解决方案使用了一个信号量数组，每个信号量分别对应一个哲学家，这样，当所需的叉子被占用时，想进餐的哲学家可以阻塞。注意，每个进程将过程philosopher作为主代码运行。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#define N 5 /* 哲学家数目 */#define LEFT (i+N-1)%N /* i的左邻号码 */#define RIGHT (i+1)%N /* i的右邻号码 */#define THINKING 0 /* 哲学家正在思考 */#define HUNGRY 1 /* 哲学家想取得叉子 */#define EATING 2 /* 哲学家正在吃面 */typedef int semaphore;int state[N]; /* 记录每个人状态的数组 */semaphore mutex=1; /* 临界区互斥 */semaphore s[N]; /* 每个哲学家一个信号量 */void philosopher(int i) /* i：哲学家号码，从0到N-1 */{ while(TRUE) { think(); /* 哲学家正在思考 */ take_forks(i); /* 需要两把叉子，或者阻塞 */ eat(); /* 进餐 */ put_forks(i); /* 把两把叉子同时放回桌子 */ }}void take_forks(int i) /* i：哲学家号码，从0到N-1 */{ down(&amp;mutex); /* 进人临界区 */ state[i]=HUNGRY; /* 记录下哲学家i饥饿的事实 */ test(i); /* 试图得到两把叉子 */ down(&amp;s[i]); /* 如果得不到叉子就阻塞 */}void put_forks(i) /* i：哲学家号码，从0到N-1 */{ down(&amp;mutex); /* 进人临界区 */ state[i]=THINKING; /* 哲学家进餐结束 */ test(LEFT); /* 看一下左邻居现在是否能进餐 */ test(RIGHT); /* 看一下右邻居现在是否能进餐 */ up(&amp;mutex); /* 离开临界区 */}void test(i) /* i：哲学家号码，从0到N-1 */{ if(state[i]==HUNGRY &amp;&amp; state[LEFT]!=EATING&amp;&amp;state[RIGHT]!=EATING){ state[i]=EATING; up(&amp;s[i]); }}","link":"/2019/07/dining_philosophers_problem.html"},{"title":"经典IPC问题 - 读者-写者问题","text":"读者-写者问题（Courtois et al，1971）为数据库访问建立了一个模型。例如，设想一个飞机订票系统，其中有许多竞争的进程试图读写其中的数据。多个进程同时读是可以接受的，但如果一个进程正在更新数据库，则所有其他进程都不能访问数据库，即便是读操作也不行。 这里的问题是如何对读者和写者进行编程。下面给出了一种解法（允许多个读者操作数据库，写者可能被饿死）。 123456789101112131415161718192021222324252627282930313233typedef int semaphore;semaphore mutex = 1; /* 控制对读者数量rc的访问 */semaphore db = 1; /* 控制对数据库的访问 */int rc = 0;void reader(void){ while (TRUE) { down (&amp;mutex); rc = rc + 1; if (rc == 1) down(&amp;db); up(&amp;mutex); read_db(); down (&amp;mutex); rc = rc - 1; if (rc == 0) up(&amp;db); up (&amp;mutex); ... }}void writer(void){ while(true) { down(&amp;db); write_db(); up(&amp;db); }} 该解法中，第一个读者对信号量db执行down操作。随后的读者只是递增一个计数器rc。当读者离开时，它们递减这个计数器，而最后一个读者则对db执行up操作，这样就允许一个阻塞的写者（如果存在）访问数据库。 现在假设一个写者到来，由于写操作是排他的，所以该写者不能访问数据库，而是被挂起。随后，又有读者出现，这样只要有一个读者活跃，随后而来的读者就都被允许访问数据库。这种策略的结果是只要有读者陆续到来，它们一来就被允许进入，而写者将一直被挂起直到没有一个读者为止。 为了防止这种情况，程序可以略做如下改动：当一个读者到来而正有一个写者在等待时，则读者被挂在写者后边，而不是立即进入。这样，写者只需等待它到来时就处于活跃状态的读者结束，而不用等那些在它后边到来的读者。这种解法的缺点是并发性较低，从而性能较差。 （Courtois 1971）给出的写者优先的解法123456789101112131415161718192021222324252627282930313233343536373839404142typedef int semaphore;semaphore mutex_rc = 1, mutex_wc = 1; /* 控制对读者写者数量的控制 */semaphore w = 1, r = 1; /* 控制对数据库的访问 */int rc = 0, wc = 0; /* 读者数量、写者数量 */void reader(void){ while (TRUE) { down (&amp;mutex_rc); down (&amp;r); rc = rc + 1; if (rc == 1) down(&amp;w); up (&amp;r) up (&amp;mutex_rc); read_db(); down (&amp;mutex_rc); rc = rc - 1; if (rc == 0) up(&amp;w); up (&amp;mutex_rc); }}void writer(void){ while(TURE) { down (&amp;mutex_wc); wc = wc + 1; if (wc == 1) down(&amp;r); up (&amp;mutex_wc); down(&amp;w); write_db(); up(&amp;w); down (&amp;mutex_wc); wc = wc - 1; if (wc == 0) up(&amp;r); up (&amp;mutex_wc); }}","link":"/2019/07/readers_writers_problem.html"},{"title":"算法笔记 - Dijkstra算法","text":"Dijkstra算法，译为迪杰斯特拉算法，使用了广度优先搜索解决赋权有向图或者无向图的单源最短路径问题。Dijkstra算法不采用最小优先级队列的时间复杂度是 O(|V|^2)（其中|V|为图的顶点个数）。 算法思路Dijkstra算法采用的是一种贪心的策略。 一个数组dp[]来保存源点s到各个顶点的最短距离 一个保存已经找到了最短路径的顶点的集合T（用数组T置1来表示该顶点已加入集合T，以下以~T表示未加入T的顶点集合）。 初始：dp数组初始化为INF（无穷大），将源点s的dp值被赋为0（dp[s]=0），集合T为空（PS：第一次循环必定找到源点s加入T）。 循环： 从~T中找到当前能到达的最近的顶点j（即dp数组中值最小的dp[j]），并且把该点j加入到T中，此时完成一个顶点； 我们需要看看新加入的顶点j是否可以到达~T中的其他顶点，并且看一下通过该顶点j到达其他点的路径长度是否比之前的最短路径还要短，如果是，那么就更新源点s到这些顶点的最短路径值（dp[]数组）。 然后，重复上述动作，直到T中包含了图的所有顶点。至此，dp[]中保存源点s到各个顶点的最短距离(dp[j]即源点s到j的最短路径）。 以下动图取自维基百科 代码实现若想获得源点s到所有可达顶点的最短路径，去掉参数e和相关判断。 123456789101112131415161718192021222324252627282930313233343536373839404142/* 1. 初始化图的邻接矩阵，都是不可达；根据输入赋值，给邻接矩阵赋值 */const int INF = __INT_MAX__;fill(v[0], v[0] + n*n, INF);.../* 2. 调用 dijkstra 方法 */void dijkstra(int s, int e, int n){ /* s:起点 e:终点 n:顶点个数 */ int dp[n], T[n]; /* 初始 */ fill(dp, dp + n, INF); fill(T, T + n, 0); dp[s] = 0; /* 循环 */ while (true) { int minp = INF, j = -1; /* 1. 查找不在T中且dp值最小的顶点，并将顶点j加入集合T */ for(int i = 0; i &lt; n; i++){ if(T[i] == 0 &amp;&amp; dp[i] &lt; minp){ j = i; minp = dp[i]; } } if(j == -1) { break; /* j == -1，则表示有些顶点从源点出发是不可达的，也可以退出循环 */ } T[j] = 1; if(j == e) { /* 查找到指定终点时，可以减少循环次数 */ break; } /* 2. 利用新获得的dp[j]更新所有未在T集合中的顶点的dp值 */ for(int i = 0; i &lt; n; i++){ if(T[i] == 0){ if(v[j][i] != INF) { /* j到i可达 */ if(dp[j] + v[j][i] &lt; dp[i]){ dp[i] = dp[j] + v[j][i]; // 如果要记录路径，只需要在这将 path[i] 的路径更新为 path[j] + i; } } } } }}","link":"/2019/06/algorithm_dijkstra.html"}],"tags":[{"name":"website","slug":"website","link":"/tags/website/"},{"name":"crontab","slug":"crontab","link":"/tags/crontab/"},{"name":"github","slug":"github","link":"/tags/github/"},{"name":"ssh","slug":"ssh","link":"/tags/ssh/"},{"name":"webhook","slug":"webhook","link":"/tags/webhook/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"windows","slug":"windows","link":"/tags/windows/"},{"name":"lychee","slug":"lychee","link":"/tags/lychee/"},{"name":"hackintosh","slug":"hackintosh","link":"/tags/hackintosh/"},{"name":"ubuntu","slug":"ubuntu","link":"/tags/ubuntu/"},{"name":"snap","slug":"snap","link":"/tags/snap/"},{"name":"chrome","slug":"chrome","link":"/tags/chrome/"},{"name":"websocket","slug":"websocket","link":"/tags/websocket/"},{"name":"nginx","slug":"nginx","link":"/tags/nginx/"},{"name":"redis","slug":"redis","link":"/tags/redis/"},{"name":"linux0.12","slug":"linux0-12","link":"/tags/linux0-12/"},{"name":"bochs","slug":"bochs","link":"/tags/bochs/"},{"name":"os","slug":"os","link":"/tags/os/"},{"name":"ipc","slug":"ipc","link":"/tags/ipc/"},{"name":"dijkstra","slug":"dijkstra","link":"/tags/dijkstra/"}],"categories":[{"name":"c","slug":"c","link":"/categories/c/"},{"name":"base","slug":"base","link":"/categories/base/"},{"name":"ops","slug":"ops","link":"/categories/ops/"},{"name":"others","slug":"others","link":"/categories/others/"},{"name":"other","slug":"other","link":"/categories/other/"},{"name":"code-read","slug":"code-read","link":"/categories/code-read/"},{"name":"linux0.12","slug":"code-read/linux0-12","link":"/categories/code-read/linux0-12/"},{"name":"redis","slug":"code-read/redis","link":"/categories/code-read/redis/"},{"name":"os","slug":"base/os","link":"/categories/base/os/"},{"name":"algorithm","slug":"base/algorithm","link":"/categories/base/algorithm/"}]}